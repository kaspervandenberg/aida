<?xml version="1.0" encoding="UTF-8"?>
<s:scufl xmlns:s="http://org.embl.ebi.escience/xscufl/0.1alpha" version="0.2" log="0">
  <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:618ac202-acf6-4695-bdc6-ca0078be3649" author="Marco Roos (AID)" title="BioAID_ProteinDiscovery_filterOnHumanUniprot_perDoc_html">This workflow finds proteins relevant to the query string via the following steps:
1. A user query: a single gene/protein name. E.g.: (EZH2 OR "Enhancer of Zeste").
2. Retrieve documents: finds 'maximumNumberOfHits' relevant documents (abstract+title) based on query (the AIDA service inside is based on Apache's Lucene)
3. Discover proteins: extract proteins discovered in the set of relevant abstracts with a 'named entity recognizer' trained on genomic terms using a Bayesian approach; the AIDA service inside is based on LingPipe. This subworkflow also 'filters' false positives from the discovered protein by requiring a discovery has a valid UniProt ID. Martijn Schuemie's service to do that contains only human UniProt IDs, which is why this workflow only works for human proteins.

Workflow by Marco Roos (AID = Adaptive Information Disclosure, University of Amsterdam; http://adaptivedisclosure.org)

Text mining services by Sophia Katrenko and Edgar Meij (AID), and Martijn Schuemie (BioSemantics, Erasmus University Rotterdam).

Changes to our original BioAID_DiseaseDiscovery workflow:
   * Stops at protein discovery
   * Use of Martijn Schuemie's synsets service to
       * add synonyms to the query.
       * provide uniprot ids to discovered proteins
       * filter false positive discoveries, only proteins with a uniprot id go through; this introduces some false negatives (e.g. discovered proteins with a name shorter than 3 characters)
   * Counting of results in various ways, but no outputs defined in this simplified workflow.
   * Output into simple html table.</s:workflowdescription>
  <s:processor name="search_field" boring="true">
    <s:stringconstant>content</s:stringconstant>
  </s:processor>
  <s:processor name="DummyRankScore" boring="true">
    <s:stringconstant>0</s:stringconstant>
  </s:processor>
  <s:processor name="Document_index" boring="true">
    <s:stringconstant>MedLine_new</s:stringconstant>
  </s:processor>
  <s:processor name="Concatenate_URLstub_ID">
    <s:local>org.embl.ebi.escience.scuflworkers.java.StringConcat</s:local>
  </s:processor>
  <s:processor name="PubMedURLstub" boring="true">
    <s:stringconstant>http&amp;#58;//www.ncbi.nlm.nih.gov/sites/entrez?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;list_uids=</s:stringconstant>
  </s:processor>
  <s:processor name="StructureLists">
    <s:arbitrarywsdl>
      <s:wsdl>http://aida.science.uva.nl:9999/axis/DiscoveredProteins_html.jws?wsdl</s:wsdl>
      <s:operation>StructureLists</s:operation>
    </s:arbitrarywsdl>
    <s:iterationstrategy>
      <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:dot>
          <i:iterator name="query_protein" />
          <i:iterator name="ranking_score" />
        </i:dot>
        <i:dot>
          <i:iterator name="discovered_protein" />
          <i:iterator name="discovered_uniprot_id" />
          <i:iterator name="pubmed_id" />
        </i:dot>
      </i:cross>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="DiscoveredProteinsToHtmlTable">
    <s:arbitrarywsdl>
      <s:wsdl>http://aida.science.uva.nl:9999/axis/DiscoveredProteins_html.jws?wsdl</s:wsdl>
      <s:operation>DiscoveredProteinsToHtmlTable</s:operation>
    </s:arbitrarywsdl>
  </s:processor>
  <s:processor name="default_max_hits" boring="true">
    <s:description>Default maximum number of documents to retrieve from medline by the query from which to extract proteins.</s:description>
    <s:stringconstant>10</s:stringconstant>
  </s:processor>
  <s:processor name="CountDocuments">
    <s:beanshell>
      <s:scriptvalue>count = list.size();</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="l('text/plain')">list</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="'text/plain'">count</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
  </s:processor>
  <s:processor name="Clone">
    <s:beanshell>
      <s:scriptvalue>import java.util.*;

List newlist = new ArrayList();

for (int i=0; i&lt;((int) Integer.parseInt(copy_number.toString())); i++) {
	newlist.add(input);
}

clones=newlist;</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="'text/plain'">copy_number</s:beanshellinput>
        <s:beanshellinput s:syntactictype="'text/plain'">input</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="'text/plain'">clones</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
    <s:iterationstrategy>
      <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:iterator name="input" />
        <i:iterator name="copy_number" />
      </i:dot>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="Retrieve_documents">
    <s:description>This workflow retrieves relevant documents, based on a query optimized by adding a string to the original query that will rank the search output according to the most recent years. The added string adds years with priorities (most recent is highest); it starts at 2007.</s:description>
    <s:defaults>
      <s:default name="maxHits">10</s:default>
    </s:defaults>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:dd1e2961-a1ca-4902-9bfb-2b776a4399ee" author="Marco Roos (AID)" title="Retrieve_bio_documents">This workflow retrieves relevant documents, based on a query optimized by adding a string to the original query that will rank the search output according to the most recent years. The added string adds years with priorities (most recent is highest); it starts at 2007.</s:workflowdescription>
        <s:processor name="Retrieve">
          <s:description>This workflow applies the search web service from the AIDA toolbox.

Comments:
This search service is based on lucene defaults; it may be necessary to optimize the querystring to adopt the behaviour to what is most relevant in a particular domain (e.g. for medline prioritizing based on publication date is useful). Lucene favours shorter sentences, which may be bad for subsequent information extraction.</s:description>
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:858efe24-26c0-4090-be46-c9a5b4f21cad" author="Marco Roos" title="Retrieve_documents_MR1">This workflow applies the search web service from the AIDA toolbox.

Comments:
This search service is based on lucene defaults; it may be necessary to optimize the querystring to adopt the behaviour to what is most relevant in a particular domain (e.g. for medline prioritizing based on publication date is useful). Lucene favours shorter sentences, which may be bad for subsequent information extraction.</s:workflowdescription>
              <s:processor name="search">
                <s:arbitrarywsdl>
                  <s:wsdl>http://ws.adaptivedisclosure.org/axis/services/SearcherWS?wsdl</s:wsdl>
                  <s:operation>search</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="document_index" sink="search:index" />
              <s:link source="maxHits" sink="search:maxHits" />
              <s:link source="queryString" sink="search:queryString" />
              <s:link source="search_field" sink="search:defaultField" />
              <s:link source="search:searchReturn" sink="relevant_documents" />
              <s:source name="queryString" />
              <s:source name="document_index" />
              <s:source name="search_field" />
              <s:source name="maxHits" />
              <s:sink name="relevant_documents">
                <s:metadata>
                  <s:mimeTypes>
                    <s:mimeType>text/xml</s:mimeType>
                  </s:mimeTypes>
                </s:metadata>
              </s:sink>
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:processor name="Biooptimize_query">
          <s:description>This workflow does four things:
1. it retrieves documents relevant for the query string
2. it discovers entities in those documents, these are considered relevant entities
3. it filters proteins from those entities (on the tag protein_molecule)
4. it removes all terms from the list produced by 3 (query terms temporarily considered proteins)

ToDo
* Replace step 4 by the following procedure:
  1. remove the query terms from the output of NER (probably by a regexp matching on what is inside the tag, possibly case-insensitive)
  2. remove tag_as_protein_molecule (obsolete)
* Add synonym service/workflow

Note that Remove_inputquery has an alternative iteration strategy (dot product instead of cross product). Idem for 'Join' in 'SplitQuery'.</s:description>
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:3d2eebb7-0b04-4979-9aa9-3d39b1464216" author="Marco Roos" title="Lucene_bioquery_optimizer_MR1">This workflow does four things:
1. it retrieves documents relevant for the query string
2. it discovers entities in those documents, these are considered relevant entities
3. it filters proteins from those entities (on the tag protein_molecule)
4. it removes all terms from the list produced by 3 (query terms temporarily considered proteins)

ToDo
* Replace step 4 by the following procedure:
  1. remove the query terms from the output of NER (probably by a regexp matching on what is inside the tag, possibly case-insensitive)
  2. remove tag_as_protein_molecule (obsolete)
* Add synonym service/workflow

Note that Remove_inputquery has an alternative iteration strategy (dot product instead of cross product). Idem for 'Join' in 'SplitQuery'.</s:workflowdescription>
              <s:processor name="Lucene_year_priorities" boring="true">
                <s:stringconstant>year:(2007^10 2006^9 2005^8 2004^7 2004^6 2003^5 2002^4 2001^3 2000^2 1999^1)</s:stringconstant>
              </s:processor>
              <s:processor name="Prioritise_lucene_query">
                <s:beanshell>
                  <s:scriptvalue>StringBuffer temp=new StringBuffer();
temp.append("+(");
temp.append(query_string);
temp.append(") +");
temp.append(priority_string);
String lucene_query = temp.toString();</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">query_string</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">priority_string</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">lucene_query</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:link source="Lucene_year_priorities:value" sink="Prioritise_lucene_query:priority_string" />
              <s:link source="query_string" sink="Prioritise_lucene_query:query_string" />
              <s:link source="Prioritise_lucene_query:lucene_query" sink="optimized_lucene_query" />
              <s:source name="query_string">
                <s:metadata>
                  <s:description>Lucene query string</s:description>
                </s:metadata>
              </s:source>
              <s:sink name="optimized_lucene_query" />
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:link source="query_string" sink="Biooptimize_query:query_string" />
        <s:link source="Biooptimize_query:optimized_lucene_query" sink="Retrieve:queryString" />
        <s:link source="document_index" sink="Retrieve:document_index" />
        <s:link source="maxHits" sink="Retrieve:maxHits" />
        <s:link source="search_field" sink="Retrieve:search_field" />
        <s:link source="Retrieve:relevant_documents" sink="relevant_documents" />
        <s:source name="query_string" />
        <s:source name="document_index" />
        <s:source name="search_field" />
        <s:source name="maxHits" />
        <s:sink name="relevant_documents">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/xml</s:mimeType>
            </s:mimeTypes>
          </s:metadata>
        </s:sink>
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="SliceOutListLevel_bs">
    <s:beanshell>
      <s:scriptvalue>List tmpList = new ArrayList();
Iterator iterator=inListOfLists.iterator();
Iterator iterator2;

while (iterator.hasNext()) {
	iterator2=iterator.next().iterator();
	while (iterator2.hasNext()) {
		tmpList.add(iterator2.next());
	}
}

outlist=tmpList;</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="l(l(l('text/plain')))">inListOfLists</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="l(l('text/plain'))">outlist</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
  </s:processor>
  <s:processor name="htmlize_table">
    <s:description>The beanshell turns the lists into a html table. Note that I added a filter to skip discoveries that equal the query. Here is actually not the elegant place to solve that issue, but good for my purposes here (test 'run-from-myExpeirment' for end-users=bench biologists).</s:description>
    <s:beanshell>
      <s:scriptvalue>/* beanshell script to compile lists of text mining results into a table */
/* 
variables:
structuredList //  list of (query protein, discovered protein, publication) lists
*/
String html_top="&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Results of text mining workflow&lt;/title&gt;\n&lt;link href='http://www.adaptivedisclosure.org/workflows/AIDA_workflows.css' rel='stylesheet' type='text/css'/&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;div id='wrapper'&gt;\n&lt;div id='header'&gt;\n&lt;span id='aida_logo' title='Adaptive Information Disclosure Application'&gt;&lt;a href='http://adaptivedisclosure.org'&gt;Adaptive Information Disclosure Application&lt;/a&gt;&lt;/span&gt;\n&lt;span id='vle_logo' title='Virtual Laboratory for e-Science'&gt;&lt;a href='http://www.vl-e.nl/'&gt;Virtual Laboratory for e-Science&lt;/a&gt;&lt;/span&gt;\n&lt;/div&gt;&lt;!-- header --&gt;\n&lt;div id='page_title'&gt;\n&lt;h1&gt;&lt;span title='Adaptive Information Disclosure Application'&gt;AIDA&lt;/span&gt; workflow results&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- page_title --&gt;\n";

String html_top=html_top+"&lt;table align='center' summary='this table gives the results of the text mining workflow'&gt;\n&lt;caption&gt;&lt;em&gt;Results of text mining workflow&lt;/em&gt;&lt;/caption&gt;\n&lt;tr&gt;\n&lt;th&gt;Query&lt;br/&gt;protein&lt;/th&gt;\n&lt;th&gt;Associated&lt;br/&gt;with&lt;/th&gt;\n&lt;th&gt;Published in&lt;br/&gt;&lt;small&gt;(PubMed ID)&lt;/small&gt;&lt;/th&gt;\n&lt;/tr&gt;\n";

String html_bottom="&lt;/table&gt;\n\n&lt;div id='footer'&gt;\n&lt;div id='AIDA'/&gt;\n&lt;/div&gt;&lt;!-- footer --&gt;\n&lt;/div&gt;&lt;!-- wrapper --&gt;&lt;/body&gt;\n&lt;/html&gt;\n";

String qry;
String prot;
String uniprot;
String pub_id;

String prev_qry="";
String prev_prot="";
String prev_uniprot="";
String prev_pub_id="";

String tablebody="";
/*
Iterator item_iterator;
Iterator iterator = structuredList.iterator();
while ( iterator.hasNext() ) 
{
	item_iterator = iterator.next().iterator();
	qry=(String) item_iterator.next().toString();
	prot=(String) item_iterator.next().toString();
	uniprot=(String) item_iterator.next().toString();
	pub_id=(String) item_iterator.next().toString();
	
	if (!qry.equals(prot)) {
		if (qry.equals(prev_qry)) { qry=",,"; } else { prev_qry=qry; }
		if (prot.equals(prev_prot)) { prot=",,"; } else { prev_prot = prot; }
		if (uniprot.equals(prev_uniprot)) { uniprot=",,"; iHopString=""; } else { prev_uniprot = uniprot;  iHopString="&lt;small&gt;&lt;sup&gt;&lt;a href='http://www.ihop-net.org/UniPub/iHOP/?search="+uniprot+"&amp;field=UNIPROT__AC&amp;ncbi_tax_id=9606&amp;organism_syn='&gt;iHop&lt;/a&gt;&lt;/sup&gt;&lt;/small&gt;"; }
		if (pub_id.equals(prev_pub_id)) { pub_id=",,"; } else {prev_pub_id = pub_id; }
		
		tablebody=tablebody+"&lt;tr&gt;\n&lt;td align='center'&gt;"+qry+"&lt;/td&gt;\n&lt;td align='center'&gt;&lt;a href='http://www.ncbi.nlm.nih.gov/entrez/viewer.fcgi?db=protein&amp;id="+uniprot+"' title='uniprot id: "+uniprot+"'&gt;"+prot+"&lt;/a&gt;"+iHopString+"&lt;/td&gt;&lt;td align='center' &gt;&lt;a href='http://www.ncbi.nlm.nih.gov/sites/entrez?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;list_uids="+pub_id+"'&gt;"+pub_id+"&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n";
	}
}
*/
html_table=html_top+tablebody+html_bottom;</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="l(l('text/plain'))">structuredList</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="'text/plain'">html_table</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
  </s:processor>
  <s:processor name="SliceOutListLevel_doc_ids">
    <s:beanshell>
      <s:scriptvalue>List tmpList = new ArrayList();
Iterator iterator=inListOfLists.iterator();
Iterator iterator2;

while (iterator.hasNext()) {
	iterator2=iterator.next().iterator();
	while (iterator2.hasNext()) {
		tmpList.add(iterator2.next());
	}
}

outlist=tmpList;</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="l(l(l('text/plain')))">inListOfLists</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="l(l('text/plain'))">outlist</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
  </s:processor>
  <s:processor name="Discover_HumanUniProt_proteins">
    <s:description>This workflow applies the discovery workflow built around the AIDA 'Named Entity Recognize' web service by Sophia Katrenko. It uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in a set of documents in lucene output format.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:b4c1a118-6a38-40b5-99e9-febbd3c85f2b" author="Marco Roos (AID)" title="Discover_proteins_per_document">This workflow applies the discovery workflow built around the AIDA 'Named Entity Recognize' web service by Sophia Katrenko. It uses the pre-learned genomics model, named 'MedLine', to find genomics concepts in a set of documents in lucene output format.</s:workflowdescription>
        <s:processor name="prelearned_genomics_model" boring="true">
          <s:stringconstant>MedLine</s:stringconstant>
        </s:processor>
        <s:processor name="Discover_entities">
          <s:description>This workflow contains the 'Named Entity Recognize' web service from the AIDA toolbox, created by Sophia Katrenko. It can be used to discover entities of a certain type (determined by 'learned_model') in documents provided in a lucene output format.</s:description>
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:e7ae8f2a-428f-4afd-93eb-52ccb89273e1" author="Marco Roos (AID)" title="Discover_entities">This workflow contains the 'Named Entity Recognize' web service from the AIDA toolbox, created by Sophia Katrenko. It can be used to discover entities of a certain type (determined by 'learned_model') in documents provided in a lucene output format.

Known issues:
The output of NErecognize contains concepts with / characters, breaking the xml. For post-processing its results it is better to use string manipulation than xml manipulations.
The output is per document, which means entities will  be redundant if they occur in more than one document.</s:workflowdescription>
              <s:processor name="Default_input_type" boring="true">
                <s:stringconstant>lucene</s:stringconstant>
              </s:processor>
              <s:processor name="Default_output_type" boring="true">
                <s:stringconstant>NElist</s:stringconstant>
              </s:processor>
              <s:processor name="NErecognize">
                <s:arbitrarywsdl>
                  <s:wsdl>http://ws.adaptivedisclosure.org/axis/services/NERecognizerService?wsdl</s:wsdl>
                  <s:operation>NErecognize</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:link source="input_from_lucene" sink="NErecognize:input_data" />
              <s:link source="learned_model" sink="NErecognize:r_type" />
              <s:link source="Default_input_type:value" sink="NErecognize:input_type" />
              <s:link source="Default_output_type:value" sink="NErecognize:output_type" />
              <s:link source="NErecognize:NErecognizeReturn" sink="discovered_entities" />
              <s:source name="input_from_lucene" />
              <s:source name="learned_model">
                <s:metadata>
                  <s:description>Model to discover a set of specific concepts; e.g. the prelearned model named 'MedLine' will make the service discover genomics concepts.</s:description>
                </s:metadata>
              </s:source>
              <s:sink name="discovered_entities">
                <s:metadata>
                  <s:mimeTypes>
                    <s:mimeType>text/rdf</s:mimeType>
                    <s:mimeType>text/xml</s:mimeType>
                  </s:mimeTypes>
                  <s:description>Entities discoverd in documents provided in lucene output format.</s:description>
                </s:metadata>
              </s:sink>
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:processor name="Extract_ProteinsPerDocID">
          <s:description>This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:description>
          <s:workflow>
            <s:scufl version="0.2" log="0">
              <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:df6063f9-b469-4d56-aecc-a62db4bcb3ad" author="Marco Roos (AID)" title="Extract_proteins_per_xmldoc">This workflow filters protein_molecule-labeled terms from an input string(list). The result is a tagged list of proteins (disregarding false positives in the input).

Internal information:
This workflow is a copy of 'filter_protein_molecule_MR3' used for the NBIC poster (now in Archive).</s:workflowdescription>
              <s:processor name="DocID_xpath" boring="true">
                <s:stringconstant>//doc/@id</s:stringconstant>
              </s:processor>
              <s:processor name="DocPart_xpath" boring="true">
                <s:stringconstant>//doc</s:stringconstant>
              </s:processor>
              <s:processor name="XPath_DocID_From_Text">
                <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
              </s:processor>
              <s:processor name="XPath_protein_From_Text">
                <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
              </s:processor>
              <s:processor name="Filter2">
                <s:defaults>
                  <s:default name="regex">.+</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="protein_molecule_xpath" boring="true">
                <s:stringconstant>//protein_molecule</s:stringconstant>
              </s:processor>
              <s:processor name="Remove_duplicate_strings">
                <s:local>org.embl.ebi.escience.scuflworkers.java.StringStripDuplicates</s:local>
              </s:processor>
              <s:processor name="getUniprotID">
                <s:arbitrarywsdl>
                  <s:wsdl>http://bubbles.biosemantics.org:8180/axis/services/SynsetServer/SynsetServer.jws?wsdl</s:wsdl>
                  <s:operation>getUniprotID</s:operation>
                </s:arbitrarywsdl>
              </s:processor>
              <s:processor name="XPath_DocPart_From_Text">
                <s:local>net.sourceforge.taverna.scuflworkers.xml.XPathTextWorker</s:local>
              </s:processor>
              <s:processor name="Filter1">
                <s:defaults>
                  <s:default name="regex">.+</s:default>
                </s:defaults>
                <s:local>org.embl.ebi.escience.scuflworkers.java.FilterStringList</s:local>
              </s:processor>
              <s:processor name="UniProtOrNot">
                <s:beanshell>
                  <s:scriptvalue>Iterator i;

if (uniprotIDlist.isEmpty()) {
	uniprotID_or_False = "False";
} else {
	uniprotID_or_False = (String) uniprotIDlist.iterator().next().toString();
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="l('text/plain')">uniprotIDlist</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">uniprotID_or_False</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
              </s:processor>
              <s:processor name="FilterTrueProteinByUniProtID">
                <s:beanshell>
                  <s:scriptvalue>if (uniprot!="False") {
	true_protein=protein;
	true_uniprot=uniprot;
}</s:scriptvalue>
                  <s:beanshellinputlist>
                    <s:beanshellinput s:syntactictype="'text/plain'">protein</s:beanshellinput>
                    <s:beanshellinput s:syntactictype="'text/plain'">uniprot</s:beanshellinput>
                  </s:beanshellinputlist>
                  <s:beanshelloutputlist>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_protein</s:beanshelloutput>
                    <s:beanshelloutput s:syntactictype="'text/plain'">true_uniprot</s:beanshelloutput>
                  </s:beanshelloutputlist>
                  <s:dependencies s:classloader="iteration" />
                </s:beanshell>
                <s:iterationstrategy>
                  <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
                    <i:iterator name="uniprot" />
                    <i:iterator name="protein" />
                  </i:dot>
                </s:iterationstrategy>
              </s:processor>
              <s:link source="FilterTrueProteinByUniProtID:true_protein" sink="Filter2:stringlist" />
              <s:link source="FilterTrueProteinByUniProtID:true_uniprot" sink="Filter1:stringlist" />
              <s:link source="Remove_duplicate_strings:strippedlist" sink="getUniprotID:term" />
              <s:link source="UniProtOrNot:uniprotID_or_False" sink="FilterTrueProteinByUniProtID:uniprot" />
              <s:link source="XPath_protein_From_Text:nodelist" sink="Remove_duplicate_strings:stringlist" />
              <s:link source="getUniprotID:getUniprotIDReturn" sink="UniProtOrNot:uniprotIDlist" />
              <s:link source="input_string" sink="XPath_DocID_From_Text:xml-text" />
              <s:link source="DocID_xpath:value" sink="XPath_DocID_From_Text:xpath" />
              <s:link source="input_string" sink="XPath_DocPart_From_Text:xml-text" />
              <s:link source="DocPart_xpath:value" sink="XPath_DocPart_From_Text:xpath" />
              <s:link source="Remove_duplicate_strings:strippedlist" sink="FilterTrueProteinByUniProtID:protein" />
              <s:link source="XPath_DocPart_From_Text:nodelistAsXML" sink="XPath_protein_From_Text:xml-text" />
              <s:link source="protein_molecule_xpath:value" sink="XPath_protein_From_Text:xpath" />
              <s:link source="Filter1:filteredlist" sink="uniprotID" />
              <s:link source="Filter2:filteredlist" sink="protein_molecule" />
              <s:link source="XPath_DocID_From_Text:nodelist" sink="doc_id" />
              <s:source name="input_string">
                <s:metadata>
                  <s:mimeTypes>
                    <s:mimeType>text/plain</s:mimeType>
                  </s:mimeTypes>
                  <s:description>Example:
&lt;result_final&gt;&lt;doc id="15208672"&gt;&lt;other_name&gt;Replicative&lt;/other_name&gt;&lt;other_name&gt;cell&lt;/other_name&gt;&lt;cell_type&gt;damaged&lt;/cell_type&gt;&lt;other_name&gt;tumor&lt;/other_name&gt;&lt;protein_molecule&gt;tumor&lt;/protein_molecule&gt;&lt;protein_molecule&gt;p53&lt;/protein_molecule&gt;&lt;other_name&gt;EZH2&lt;/other_name&gt;&lt;protein_molecule&gt;p53&lt;/protein_molecule&gt;&lt;other_name&gt;epigenetic&lt;/other_name&gt;&lt;other_name&gt;genetic&lt;/other_name&gt;&lt;other_name&gt;EZH2&lt;/other_name&gt;&lt;tissue&gt;tumors&lt;/tissue&gt;&lt;protein_molecule&gt;p53&lt;/protein_molecule&gt;&lt;other_name&gt;cancer&lt;/other_name&gt;&lt;/doc&gt;&lt;doc id="15520282"&gt;&lt;protein_molecule&gt;Ezh2&lt;/protein_molecule&gt;&lt;protein_molecule&gt;Polycomb&lt;/protein_molecule&gt;&lt;protein_complex&gt;PRC3&lt;/protein_complex&gt;&lt;other_organic_compound&gt;histone&lt;/other_organic_compound&gt;&lt;other_name&gt;HKMT&lt;/other_name&gt;&lt;protein_molecule&gt;Ezh2&lt;/protein_molecule&gt;&lt;protein_molecule&gt;HDAC1&lt;/protein_molecule&gt;&lt;protein_family_or_group&gt;YY1&lt;/protein_family_or_group&gt;&lt;other_organic_compound&gt;H3&lt;/other_organic_compound&gt;&lt;protein_molecule&gt;MyoD&lt;/protein_molecule&gt;&lt;protein_molecule&gt;SRF&lt;/protein_molecule&gt;&lt;DNA_family_or_group&gt;chromatin&lt;/DNA_family_or_group&gt;&lt;other_organic_compound&gt;H3&lt;/other_organic_compound&gt;&lt;protein_complex&gt;Ezh2&lt;/protein_complex&gt;&lt;protein_family_or_group&gt;positive&lt;/protein_family_or_group&gt;&lt;DNA_domain_or_region&gt;genomic&lt;/DNA_domain_or_region&gt;&lt;other_name&gt;muscle&lt;/other_name&gt;&lt;other_name&gt;cell&lt;/other_name&gt;&lt;/doc&gt;&lt;/result_final&gt;</s:description>
                </s:metadata>
              </s:source>
              <s:sink name="protein_molecule" />
              <s:sink name="uniprotID" />
              <s:sink name="doc_id" />
            </s:scufl>
          </s:workflow>
        </s:processor>
        <s:link source="documents_from_lucene" sink="Discover_entities:input_from_lucene" />
        <s:link source="Discover_entities:discovered_entities" sink="Extract_ProteinsPerDocID:input_string" />
        <s:link source="Extract_ProteinsPerDocID:doc_id" sink="doc_ids" />
        <s:link source="Extract_ProteinsPerDocID:protein_molecule" sink="discovered_proteins" />
        <s:link source="Extract_ProteinsPerDocID:uniprotID" sink="discovered_uniprot_ids" />
        <s:link source="prelearned_genomics_model:value" sink="Discover_entities:learned_model" />
        <s:source name="documents_from_lucene" />
        <s:sink name="discovered_proteins">
          <s:metadata>
            <s:mimeTypes>
              <s:mimeType>text/rdf</s:mimeType>
              <s:mimeType>text/xml</s:mimeType>
            </s:mimeTypes>
          </s:metadata>
        </s:sink>
        <s:sink name="discovered_uniprot_ids" />
        <s:sink name="doc_ids" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="CountProteins">
    <s:beanshell>
      <s:scriptvalue>count = list.size();</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="l('text/plain')">list</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="'text/plain'">count</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
  </s:processor>
  <s:processor name="ConcatenateLists">
    <s:beanshell>
      <s:scriptvalue>/*
variables
item1
item2
item3
*/
import java.util.*;

List tmpList = new ArrayList();

tmpList.add(item1);
tmpList.add(item2);
tmpList.add(item3);
tmpList.add(item4);

outlist=tmpList;</s:scriptvalue>
      <s:beanshellinputlist>
        <s:beanshellinput s:syntactictype="'text/plain'">item1</s:beanshellinput>
        <s:beanshellinput s:syntactictype="'text/plain'">item2</s:beanshellinput>
        <s:beanshellinput s:syntactictype="'text/plain'">item3</s:beanshellinput>
        <s:beanshellinput s:syntactictype="'text/plain'">item4</s:beanshellinput>
      </s:beanshellinputlist>
      <s:beanshelloutputlist>
        <s:beanshelloutput s:syntactictype="l('text/plain')">outlist</s:beanshelloutput>
      </s:beanshelloutputlist>
      <s:dependencies s:classloader="iteration" />
    </s:beanshell>
    <s:iterationstrategy>
      <i:cross xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
        <i:dot>
          <i:iterator name="item4" />
          <i:iterator name="item3" />
          <i:iterator name="item2" />
        </i:dot>
        <i:iterator name="item1" />
      </i:cross>
    </s:iterationstrategy>
  </s:processor>
  <s:processor name="SynonymsToQuery">
    <s:description>This workflow creates a query string from the query term using Martijn Schuemie's synonym service. The service is limited to proteins, enzymes and genes. An input query that is a boolean string will be split and processed, but the boolean logic of the input query will be lost.</s:description>
    <s:workflow>
      <s:scufl version="0.2" log="0">
        <s:workflowdescription lsid="urn:lsid:net.sf.taverna:wfDefinition:ecb927cc-a200-4290-9342-302d5fc836ca" author="Marco Roos (AID) and Martijn Schuemie (ErasmusMC)" title="ProteinSynonymsToQuery">This workflow creates a query string from the query term using Martijn Schuemie's synonym service. The service is limited to proteins, enzymes and genes. An input query that is a boolean string will be split and processed, but the boolean logic of the input query will be lost.</s:workflowdescription>
        <s:processor name="Flatten_list">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="Flatten_list2">
          <s:local>
            org.embl.ebi.escience.scuflworkers.java.FlattenList
            <s:extensions>
              <s:flattenlist s:depth="2" />
            </s:extensions>
          </s:local>
        </s:processor>
        <s:processor name="getSynsets">
          <s:description>Protein synonym service by Martijn Schuemie, Erasmus Medical Centre, University of Rotterdam, The Netherlands.</s:description>
          <s:arbitrarywsdl>
            <s:wsdl>http://aida.science.uva.nl:8888/axis/SynsetServer.jws?wsdl</s:wsdl>
            <s:operation>getSynsets</s:operation>
          </s:arbitrarywsdl>
        </s:processor>
        <s:processor name="Concat_synonyms">
          <s:beanshell>
            <s:scriptvalue>import java.util.*;
String synstring="\"" + query_term + "\"";
String syn;
Iterator iterator = synonymlist.iterator();
while ( iterator.hasNext() ) 
	{
	synstring = synstring + " OR ";
	syn = ((String) iterator.next());
	synstring = synstring + "\"" + syn + "\"";
}
new_query = synstring;</s:scriptvalue>
            <s:beanshellinputlist>
              <s:beanshellinput s:syntactictype="l('text/plain')">synonymlist</s:beanshellinput>
              <s:beanshellinput s:syntactictype="'text/plain'">query_term</s:beanshellinput>
            </s:beanshellinputlist>
            <s:beanshelloutputlist>
              <s:beanshelloutput s:syntactictype="'text/plain'">new_query</s:beanshelloutput>
            </s:beanshelloutputlist>
            <s:dependencies s:classloader="iteration" />
          </s:beanshell>
          <s:mergemode input="synonymlist" mode="merge" />
          <s:iterationstrategy>
            <i:dot xmlns:i="http://org.embl.ebi.escience/xscufliteration/0.1beta10">
              <i:iterator name="query_term" />
              <i:iterator name="synonymlist" />
            </i:dot>
          </s:iterationstrategy>
        </s:processor>
        <s:processor name="SplitQuery">
          <s:workflow>
            <s:xscufllocation>http://rdf.adaptivedisclosure.org/~marco/BioAID/Public/Workflows/UtilityWorkflows/Split_query_string_MR3.xml</s:xscufllocation>
          </s:workflow>
        </s:processor>
        <s:link source="Flatten_list:outputlist" sink="Flatten_list2:inputlist" />
        <s:link source="SplitQuery:queryList" sink="getSynsets:term" />
        <s:link source="getSynsets:getSynsetsReturn" sink="Flatten_list:inputlist" />
        <s:link source="query_term" sink="Concat_synonyms:query_term" />
        <s:link source="query_term" sink="SplitQuery:queryString" />
        <s:link source="Concat_synonyms:new_query" sink="new_query" />
        <s:link source="Flatten_list2:outputlist" sink="Concat_synonyms:synonymlist" />
        <s:link source="Flatten_list2:outputlist" sink="synonyms" />
        <s:source name="query_term">
          <s:metadata>
            <s:description>Query term without quotes, only synonyms of proteins, enzymes and genes will be returned. Boolean queries will be processed, but the input boolean logic will be lost.
E.g. 'EZH2'</s:description>
          </s:metadata>
        </s:source>
        <s:sink name="synonyms" />
        <s:sink name="new_query" />
      </s:scufl>
    </s:workflow>
  </s:processor>
  <s:processor name="Flatten_list">
    <s:local>
      org.embl.ebi.escience.scuflworkers.java.FlattenList
      <s:extensions>
        <s:flattenlist s:depth="2" />
      </s:extensions>
    </s:local>
  </s:processor>
  <s:processor name="Flatten_list1">
    <s:local>
      org.embl.ebi.escience.scuflworkers.java.FlattenList
      <s:extensions>
        <s:flattenlist s:depth="2" />
      </s:extensions>
    </s:local>
  </s:processor>
  <s:processor name="Flatten_list2">
    <s:local>
      org.embl.ebi.escience.scuflworkers.java.FlattenList
      <s:extensions>
        <s:flattenlist s:depth="2" />
      </s:extensions>
    </s:local>
  </s:processor>
  <s:link source="Clone:clones" sink="SliceOutListLevel_doc_ids:inListOfLists" />
  <s:link source="CountProteins:count" sink="Clone:copy_number" />
  <s:link source="Discover_HumanUniProt_proteins:discovered_proteins" sink="ConcatenateLists:item2" />
  <s:link source="Discover_HumanUniProt_proteins:discovered_proteins" sink="CountProteins:list" />
  <s:link source="Discover_HumanUniProt_proteins:discovered_uniprot_ids" sink="ConcatenateLists:item3" />
  <s:link source="Discover_HumanUniProt_proteins:doc_ids" sink="Clone:input" />
  <s:link source="Discover_HumanUniProt_proteins:doc_ids" sink="Concatenate_URLstub_ID:string2" />
  <s:link source="Discover_HumanUniProt_proteins:doc_ids" sink="CountDocuments:list" />
  <s:link source="Document_index:value" sink="Retrieve_documents:document_index" />
  <s:link source="PubMedURLstub:value" sink="Concatenate_URLstub_ID:string1" />
  <s:link source="Retrieve_documents:relevant_documents" sink="Discover_HumanUniProt_proteins:documents_from_lucene" />
  <s:link source="query_protein" sink="ConcatenateLists:item1" />
  <s:link source="SliceOutListLevel_doc_ids:outlist" sink="ConcatenateLists:item4" />
  <s:link source="default_max_hits:value" sink="Retrieve_documents:maxHits" />
  <s:link source="query_protein" sink="SynonymsToQuery:query_term" />
  <s:link source="ConcatenateLists:outlist" sink="SliceOutListLevel_bs:inListOfLists" />
  <s:link source="Discover_HumanUniProt_proteins:discovered_proteins" sink="StructureLists:discovered_protein" />
  <s:link source="Discover_HumanUniProt_proteins:discovered_uniprot_ids" sink="StructureLists:discovered_uniprot_id" />
  <s:link source="DummyRankScore:value" sink="StructureLists:ranking_score" />
  <s:link source="Flatten_list1:outputlist" sink="Flatten_list2:inputlist" />
  <s:link source="Flatten_list2:outputlist" sink="DiscoveredProteinsToHtmlTable:structuredList" />
  <s:link source="Flatten_list:outputlist" sink="Flatten_list1:inputlist" />
  <s:link source="SliceOutListLevel_bs:outlist" sink="htmlize_table:structuredList" />
  <s:link source="SliceOutListLevel_doc_ids:outlist" sink="StructureLists:pubmed_id" />
  <s:link source="StructureLists:StructureListsReturn" sink="Flatten_list:inputlist" />
  <s:link source="SynonymsToQuery:new_query" sink="Retrieve_documents:query_string" />
  <s:link source="query_protein" sink="StructureLists:query_protein" />
  <s:link source="search_field:value" sink="Retrieve_documents:search_field" />
  <s:link source="DiscoveredProteinsToHtmlTable:DiscoveredProteinsToHtmlTableReturn" sink="discovery_html_table" />
  <s:link source="StructureLists:StructureListsReturn" sink="test_out" />
  <s:link source="htmlize_table:html_table" sink="html_table" />
  <s:source name="query_protein">
    <s:metadata>
      <s:description>A protein name to query.  A sinlge gene/protein name is expected, because the 'ProteinSynonymsToQuery' workflow is used on the query.</s:description>
    </s:metadata>
  </s:source>
  <s:sink name="html_table">
    <s:metadata>
      <s:mimeTypes>
        <s:mimeType>text/html</s:mimeType>
      </s:mimeTypes>
    </s:metadata>
  </s:sink>
  <s:sink name="discovery_html_table" />
  <s:sink name="test_out" />
</s:scufl>

