<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html
     PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<title>LingPipe: Competition</title>
<meta http-equiv="Content-type"
      content="application/xhtml+xml; charset=iso-8859-1"/>
<meta http-equiv="Content-Language"
      content="en"/>
<link href="css/lp-site.css"
      title="lp-site"
      type="text/css"
      rel="stylesheet"
      media="screen,projection,tv" />
<link href="css/lp-site-print.css"
      title="lp-site-print"
      type="text/css"
      rel="stylesheet"
      media="print,handheld,tty,aural,braille,embossed"/>
</head>

<body>

<div id="header">
<h1 id="product">LingPipe</h1><h1 id="pagetitle">Competition</h1>
<a id="logo"
   href="http://www.alias-i.com/"
  ><img src="img/logo-small.gif" alt="alias-i logo"/>
</a>
</div><!-- head -->


<div id="navig">

<!-- set class="current" for current link -->
<ul>
<li><a href="../index.html">home</a></li>

<li><a href="demos.html">demos</a></li>

<li><a href="licensing.html">license</a></li>

<li>download
<ul>
<li><a href="download.html">lingpipe core</a></li>
<li><a href="models.html">models</a></li>
</ul>
</li>

<li>docs
<ul>
<li><a href="install.html">install</a></li>
<li><a href="../demos/tutorial/read-me.html">tutorials</a></li>
<li><a href="../docs/api/index.html">javadoc</a></li>
<li><a href="faq.html">faq</a></li>
</ul>
</li>

<li>community
<ul>
<li><a href="customers.html">customers</a></li>
<li><a href="http://groups.yahoo.com/group/LingPipe/">newsgroup</a></li>
<li><a href="http://alias-i.com/blog/">blog</a></li>
<li><a href="bugs.html">bugs</a></li>
<li><a href="sandbox.html">sandbox</a></li>
<li><a class="current" href="competition.html">competition</a></li>
</ul>
</li>

<li><a href="contact.html">contact</a></li>

<li><a href="about.html">about alias-i</a></li>
</ul>

<div class="search">
<form action="http://www.google.com/search">
<p>
<input type="hidden" name="hl" value="en" />
<input type="hidden" name="ie" value="UTF-8" />
<input type="hidden" name="oe" value="UTF-8" />
<input type="hidden" name="sitesearch" value="www.alias-i.com" />
<input class="query" size="10%" name="q" value="" />
<br />
<input class="submit" type="submit" value="search" name="submit" />
</p>
</form>
</div>

</div><!-- navig -->


<div id="content" class="content">

<h2>LingPipe's Competition</h2>

<div class="sidebar">
<h2>Contributing to this Page</h2>
<p>
If you know of a natural language toolkit that's not listed on
this page, or if you have a clarification or correction for what
we list, please <a href="contact.html">contact us</a>.
</p>
</div>

<p>On this page, we break our competition down into academic
toolkits and industrial toolkits.  We only consider software
that is available for linguistic processing, not companies that
rely on linguistic processing in an application but do not
sell that technology.
</p>

<p>How does LingPipe compare to the below offerings? A few key points
to keep in mind as you browse the offerings:
</p>

<ul>

<li>We are a Geek2Geek business. Nearly every sale we have ever
made was started by a programmer with a problem to solve.
</li>

<li>We are dedicated to making it easier to use linguistics in
applications. We know that using linguistics requires a different view
of computation and want to make it part of a well rounded developer's
skill set. How?

<ul>
  <li>We document extensively, write tutorials, build demos, and
        then do it some more.
  </li>
  <li>We present LingPipe to Java groups and to students.</li>
  <li>We sponsor hobby nights at our office in Brooklyn.</li>
  <li>We release the source code. The Royalty Free License makes it
      maximally easy to prototype and experiment.</li>
</ul>
</li>

<li>We claim no "magic pixie dust" proprietary algorithms. Our goal is
to provide industrial strength implementations of proven, well
understood technologies. That said, LingPipe is used a good deal in
research systems as a foundation over which to explore new ideas.</li>

<li>We have free support on the Yahoo! group LingPipe and offer paid support
as well.</li>

</ul>


<h2>Academic Competition</h2>

<div class="sidebar">
<h2>Goals of Academic Systems</h2>
<p>
Most of the academic systems have been put together with an emphasis on
accuracy.  This is typically derived from state-of-the-art
machine learning and/or inference algorithms.  While accurate,
these methods tend to be much slower to train and decode
than the commercial systems such as LingPipe.
</p>
<p>
Some of the academic systems, such as NLTK, were defined primarily as
teaching aids.  Others, such as OpenNLP and GATE, were developed in
order to provide baseline tools to a large community.
</p>
</div>

<p>The following is a list of ongoing large-scale, multi-function
natural language toolkits that are built and distributed by academics.
</p>

<div class="sidebar">
<h2>One-off Academic Efforts</h2>
<p>
There are hundreds of software packages released by academics that
perform either a single task or illustrate a single point.  We have
compiled a list of lists of these at the bottom of the page in the:
</p>
<ul>
<li><a href="#other">Other Lists of NLP Tools Section</a></li>
</ul>

</div>

<div class="sidebar">
<h2>Search, Speech, Translation, OCR, ...?</h2>
<p>
We have intentionally not listed competitors focused on things
other than basic language processing tools.
</p>
<p>Companies in these businesses are more likely to
be LingPipe customers than LingPipe competitors.
</p>
</div>

<h3><a href="http://www.cs.wisc.edu/~bsettles/abner/">ABNER</a></h3>

<p>ABNER is a statistical named entity recognizer using linear-chain
conditional random fields (CRFs) with a variety of orthographic and
contextual features. It also has a UI for annotation. Written by Burr
Settles out of University of Wisconsin-Madison.  Released with source with
the <a href="http://www.opensource.org/licenses/cpl.php">Commons Public License</a>.
</p>

<h3><a href="http://balie.sourceforge.net/">BALIE</a></h3>
<p>
The Baseline Information Extraction (BALIE) system is a Java natural
language toolkit developed at the University of Ottawa and released
under the GNU <a
href="http://www.gnu.org/copyleft/gpl.html">General Public
License</a>.  BALIE provides language ID, sentence detection,
part of speech and named-entity recognition.  Here's the <a href="http://balie.sourceforge.net/doc/">BALIE javadoc</a>.
</p>

<h3><a href="http://garraf.epsevg.upc.es/freeling/">FreeLing</a></h3>
<p>
FreeLing is a set of C++ tools developed at the Universitat
Politècnica de Catalunya and released under the GNU <a
href="http://www.fsf.org/licenses/lgpl.html">Lesser General Public
License</a>.  Freeling provides sentence detection, morphological
analysis, named entities, POS tagging, shallow parsing, dependency
parsing and word sense disambiguation.  Here's a link to their <a
href="http://garraf.epsevg.upc.es/freeling/doc/userman/html/">user
manual</a>.
</p>

<a name="gate"/>
<h3><a href="http://gate.ac.uk/">GATE</a></h3>
<p>GATE is a Java text mining toolkit developed at the University of
Sheffield and released under the <a href="http://gate.ac.uk/gate/licence.html">GNU
Lesser General Public License</a>.  GATE
provides a general offset-oriented development/deployment
environment/framework and some rule-based tools to run within that framework.
Many other <a href="http://gate.ac.uk/gate/doc/plugins.html">GATE plugins</a>
have been contributed by Sheffield and third parties.
Here is a link to their <a href="http://gate.ac.uk/sale/tao/index.html">user guide</a> and <a href="http://www.gate.ac.uk/releases/gate-3.1-build2270-ALL/doc/javadoc/index.html">javadoc</a>.
</p>

<h3><a href="http://www.julielab.de/">JULIE</a></h3>
<p>
&quot;The JULIE Lab here offers a comprehensive NLP tool suite for the application purposes of semantic search, information extraction and text mining. Most of our continuously expanding tool suite is based on machine learning methods and thus is domain- and language independent.
</p>
<p>
One main feature is that we offer our tools both as stand-alone programs and wrapped within the UIMA framework. UIMA is an open-source , industrial-strength, scaleable and extensible platform for creating, integrating and deploying unstructured information management solutions from combinations of semantic analysis and search components. &quot;
</p>

<h3><a href="http://mallet.cs.umass.edu/index.php/Main_Page">MALLET</a></h3>
<p>
MALLET is a Java natural language toolkit developed at the University
of Massachussetts and released under the <a
href="http://www.opensource.org/licenses/cpl.php">Common Public
License</a>.  MALLET is most widely used for classification and
sequence modeling. It also includes clustering.  It provides maximum entropy
training, including conditional random fields, general undirected
graphical models, finite-state transducers, and some general numerical
optimization classes.  Here's a link to their <a
href="http://mallet.cs.umass.edu/mallet/javadoc/index.html">javadoc</a>
and their <a
href="http://mallet.cs.umass.edu/index.php/Tutorials">tutorials</a>.
</p>


<h3><a href="http://minorthird.sourceforge.net/">Minor Third</a></h3>
<p>
Minor Third is a Java natural language toolkit developed at Carnegie
Mellon University and released under the <a
href="http://www.opensource.org/licenses/bsd-license.php">BSD
License</a>.  Minor Third provides an extensive suite of general
and sequence classifiers, including KNN, active learning, SVMs,
decision trees, CRFs, CMMs, boosting, perceptrons, etc.
Here's a link to their <a
href="http://minorthird.sourceforge.net/javadoc/">javadoc</a>
and a link to their <a href="http://minorthird.sourceforge.net/AllMinorthirdDocumentation.htm">install/tutorial page</a>.
</p>

<h3><a href="http://web.media.mit.edu/~hugo/montylingua/">MontyLingua</a></h3>
<p>
MontyLingua is a free for research use, commonsense-enriched, end-to-end natural language understander for English. Feed raw English text into MontyLingua, and the output will be a semantic interpretation of that text. Perfect for information retrieval and extraction, request processing, and question answering. From English sentences, it extracts subject/verb/object tuples, extracts adjectives, noun phrases and verb phrases, and extracts people's names, places, events, dates and times, and other semantic information. MontyLingua makes traditionally difficult language processing tasks trivial!
</p>

<h3><a href="http://www.nactem.ac.uk">NaCTeM</a></h3>
<p>
The National Centre for Text Mining (NaCTeM) is the first publicly-funded text mining
  centre in the world. We provide text mining services in response to the requirements
  of the UK academic community. NaCTeM is operated by the University of Manchester with close collaboration with the University of Tokyo.
</p>
<p>
On our website, you can find pointers to sources of information about
  text mining such as links to
</p>
<ul>

    <li> text mining services provided by NaCTeM</li>

    <li> software tools, both those developed by the NaCTeM team and by other text mining groups</li>

    <li> seminars, general events, conferences and workshops</li>

    <li> tutorials and demonstrations</li>

    <li> text mining publications</li>
</ul>


<h3><a href="http://nltk.sourceforge.net/">NLTK</a></h3> <p>The
Natural Language Toolkit (NLTK) is a general Python toolkit developed
at the University of Melbourne for
natural language processing released under the GNU <a
href="http://www.gnu.org/copyleft/gpl.html">General Public
License</a>.  NLTK contains modules for heuristic and statistical
tagging (including the Brill tagger) and chunking, full parsing (CFG),
and clustering (including K-means and EM).
The <a href="http://nltk.sourceforge.net/docs.html">documentation page</a> contains pointers to tutorials and API documentation.  It's also distributed with
a range of interesting data.
</p>

<h3><a href="http://opennlp.sourceforge.net/">OpenNLP</a></h3>
<p>
OpenNLP is a heterogeneous collection of <a
href="http://opennlp.sourceforge.net/projects.html">projects</a>
distributed under a variety of open source licenses.  The main
projects being developed for OpenNLP itself include a general Java <a
href="http://maxent.sourceforge.net/">maximum entropy</a> package
released under the GNU <a
href="http://www.fsf.org/licenses/lgpl.html">Lesser General Public
License</a>.  Here's the <a
href="http://maxent.sourceforge.net/api/index.html">maxent
javadoc</a>.  There's a tools API to go with it; here's the <a
href="http://opennlp.sourceforge.net/api/index.html">tools
javadoc</a>.  The tools include statistical tokenizers, sentence
detection, name finders, part-of-speech taggers and full syntactic
(PCFG) parsing. This is one of the few packages to do coreference
resolution.
</p>

<h3><a href="http://www.informatics.susx.ac.uk/research/nlp/rasp/">RASP</a></h3>
<p>
RASP is an NLP framework for &quot;robust accurate statistical
parsing&quot;.  It is trained using the British English corpora
Susanne, LOB and BNC.  RASP includes a tokenizer, part-of-speech
tagger, hand-built FST-based morphological analyzer for English,
grammar-based parser and parse reranking model.
</p>
<p>
RASP is distributed only as an executable and licensed under its own
<a href="http://www.cstit.cl.cam.ac.uk/cgi-bin/p/licence/licence?_page=bli&amp;_id=cK">non-commercial license</a> for education or research.
</p>
<p>
There is a <a href="http://acl.ldc.upenn.edu/P/P06/P06-4020.pdf">RASP
white paper</a> describing the system, including dependency parser
accuracy evaluation, and a longer <a
href="http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-662.html">technical
report</a> about the grammar formalism used.
</p>

<h3><a href="http://nlp.stanford.edu/software/index.shtml">Stanford NLP Software</a></h3>
<p>
This is many pieces of software with Java source licensed under the
GNU <a href="http://www.gnu.org/copyleft/gpl.html">General Public
License</a>.  Tools include a part-of-speech tagger, text classifier,
and PCFG parser.  They no longer provide public access to their full JavaNLP
toolkit.
</p>


<h3><a href="http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/">TreeTagger</a></h3>

<p>TreeTagger is Helmud Schmid's multilingual part-of-speech tagger.
It has a <a
href="http://www.ims.uni-stuttgart.de/~schmid/Tagger-Licence">research-only</a>.</p>


<h3><a href="http://www.cs.waikato.ac.nz/ml/weka/">WEKA</a></h3>
<p>
WEKA is the University of Waikato's data mining software released
under the GNU <a href="http://www.gnu.org/copyleft/gpl.html">General
Public License</a>.  It's not a natural language processing toolkit,
but a very extensive general machine learning toolkit.  It provides a
nice graphical interface for evaluation and supports just about every
machine learning algorithm known to research.  It's based on Ian
Witten and Eibe Frank's book <i>Data Mining</i>. Here's a pointer to
the <a
href="http://www.cs.waikato.ac.nz/ml/weka/index_documentation.html">WEKA
documentation</a>, which includes tutorials and pointers to the
javadoc.
</p>

<h3><a href="http://www.research.ibm.com/UIMA/">UIMA</a></h3>
<p>
UIMA is IBM Research's unstructured information management
architecture released under the <a
href="http://www.opensource.org/licenses/cpl1.0.php">Common Public
License</a>.  UIMA's not really a competitor to LingPipe so much as a
general framework into which natural language processing toolks may be
embedded.  UIMA is the integration platform for DARPA's <a href="http://www.darpa.mil///ipto/programs/gale/solicitation.htm">Global Autonomous Language Exploitation</a> (GALE) project.  We have some integrations of LingPipe's chunkers into UIMA
if anyone's interested.  Here's the <a
href="http://uima.lti.cs.cmu.edu:8080/UCR/Welcome.do">UIMA Component
Repository</a> and a document on the <a
href="http://www.research.ibm.com/UIMA/UIMA%20Architecture%20Highlights.html">architectural
highlights</a>.
</p>


<h2>Industrial Competition</h2>


<p>The following is a list of competitors with quotes from their own
web pages.  We've listed technology components where we could find them.
</p>

<h3><a href="http://www.accelovation.com/index.html">Accelovation</a></h3>

<p>&quot;Accelovation's market discovery software helps business
professionals answer complex questions faster, more accurately and
with greater confidence by distilling deep meaning, purpose and
insight drawn from the Internet and subscription content.&quot;</p>

<p>Among the &quot;<a
href="http://www.accelovation.com/solutions.html">solutions</a>&quot; they
cite is text analytics, which &quot;technologies and processes for
synthesizing insights from natural language data. These tools make it
possible for a business analyst to perform a variety of research
tasks, such as drawing conclusions about consumer sentiments or
discovering new solutions to technical problems. Accelovation provides
the text analytics tools that business analysts need to conduct
research throughout the innovation process.&quot;</p>

<h3><a href="http://www.accenture.com/Global/Services/Accenture_Technology_Labs/default.htm">Accenture Technology Labs</a></h3>

<p>Accenture is offering a <a
href="http://www.accenture.com/Global/Services/Accenture_Technology_Labs/R_and_I/SentimentServices.htm">sentiment
monitoring service</a>, &quot;Sentiment Monitoring Services searches
preferred sites or newsgroups on the Internet for opinions. Using
advanced language technologies, it interprets the sentiment of the
text towards a specified product or service and then provides the user
with an analysis of the results. Sentiment Monitoring Services
combines a search agent and a perception engine to present users with
an instant gauge of market perception of any feature, product, brand
or organization. The natural language processor of the perception
engine achieves an accuracy of approximately 90 percent compared to
opinion ratings ranked manually.&quot; </p>


<h3><a href="http://www.alifemedical.com/">A-Life Medical</a></h3>

<p> &quot;A-Life Medical’s patented Natural Language Processing (NLP)
technology utilizes proprietary knowledge-bases of more than ten
million facts to automate the coding process. Our technology combined
with our software solutions and services are dramatically changing the
way healthcare codes, submits claims, collects reimbursement, as well
as improving patient care.&quot;
</p>

<p> A-Life produces <a
href="http://www.alifemedical.com/medical-coding-products/Alacer.html">Alacer</a>,
&quot;the first end-to-end practice management system that integrates
document management, real-time NLP coding, billing, collections,
denials management, and auditing into one streamlined Windows-based
platform.&quot; </p>

<h3><a href="http://alitora.com/">Alitora Systems</a></h3>

<p>&quot;Alitora System provides comprehensive software solutions for
biotech research, management, compliance, intellectual property
management and competitive intelligence. Our software enables users to
search, annotate and collaborate, seamlessly, allowing the annotation
of information as simple as a click, and collaboration as simple as a
drag-and-drop.&quot;</p>

<p>Alitora offers <a
href="http://alitora.com/kharmony.html">kHarmony</a>, which
&quot;allows users to identify concepts that are of interest, and then
search for information relating specifically to those
concepts...&quot;.  Alitora describes kHarmony as  &quot;
using proprietary graph-theoretic and information retrieval
techniques to provide structure to unstructured data, perform data
clustering, and enable visual data exploration.&quot;
</p>


<h3><a href="http://www.ariadnegenomics.com/">Ariadne Genomics</a></h3>
<p>
&quot;Ariadne develops software tools for biologists in the areas of
pathway analysis and automated scientific text processing. Ariadne
products incorporate proprietary Natural Language Processing (NLP) and
statistical algorithms designed to functionally interpret novel
genetic information.&quot;
</p>
<p>
Although they don't really sell NLP software per se, they are making
applications like their <a
href="http://www.ariadnegenomics.com/products/medscan/reader/">Medscan
Reader</a> for text data mining over biomedical research articles.  It
uses entity extraction (e.g. genes and diseases), specific relation
extraction (e.g. binding or regulation) and sentence-level search
and summarization.
</p>

<h3><a href="http://www.attensity.com">Attensity</a></h3>
<p>
&quot;Attensity's breakthrough Text Analytics solutions enable
computers to understand and process free-form text, offering
organizations the opportunity to leverage the vast amounts of
information contained in non-structured formats. The technology allows
users to extract and analyze facts like who, what, where, why, under
what conditions and to whom, as well as opinions and events found in
unstructured data.&quot;
</p>
<p>
&quot;Attensity offers a complete suite of products for Text
Analytics. The suite includes both targeted and Exhaustive Extraction
Engines that pull the information out of text and put it into a usable
format, analysis and discovery applications that allow you to explore
and make sense of the data, knowledge libraries and knowledge
engineering tools that provide the ability to define what to extract
and categories to put data in, and an integration toolkit.&quot;
</p>


<h3><a href="http://www.autonomy.com/content/home/">Autonomy</a></h3>
<p>
&quot; Autonomy is the acknowledged leader in the rapidly growing area of Meaning Based Computing (MBC).&quot;
</p>
<p>&quot;Meaning Based Computing not only uncovers, but also makes sense of, the 85% of enterprise information that is hidden to all other technologies including keyword search engines and relational databases. ...
Meaning Based Computing enables organizations to automatically form a contextual understanding of people's interests, behavior and ongoing interaction with any type of information.
...
Meaning Based Computing enables organizations to extract meaningful evidence from terabytes of email, documents, spreadsheets and other unstructured information.&quot;
</p>



<h3><a href="http://www.basistech.com/">Basis Technology</a></h3>
<p>
&quot;Basis Technology provides software solutions for extracting meaningful intelligence from unstructured text in Asian, European and Middle Eastern languages.  We help technology companies  and government organizations improve the accuracy of information retrieval, text mining and other applications through advanced linguistics.&quot;
</p>
<p>
Basis provides entity extraction in ten languages, does language
identification, as well as Chinese and Japanese character-level support.
</p>

<h3><a href="http://www.bbn.com/Products_and_Services/Unstructured_Data/index.html">BBN</a></h3>
<p>
&quot;BBN is the leader in the development of the new "Semantic Web," which will enable powerful searches and automated agents. BBN has been coordinating the work of 23 US and international research teams in conjunction with the World Wide Web Consortium and European Union collaborators to drive the transition to a semantic web.&quot;
</p>
<p>They're currently selling <a href="http://www.bbn.com/Products_and_Services/Unstructured_Data/Identifinder.html">Identifinder</a>, a named entity recognizer.
</p>


<h3><a href="http://businessobjects.com">BusinessObjects</a></h3>

<p>
&quot;Gain a more complete view of organizational performance by accessing your unstructured text data with the first and only native text analysis capabilities designed specifically to complement your BusinessObjects Enterprise and Data Integrator deployments.&quot;</p>

<p> BusinessObjects is part of <a
href="http://www.sap.com/">SAP</a>.  Among its operations is <a
href="http://www.businessobjects.com/products/platform/textanalysis/">BusinessObjects
Text Analysis</a>, which does entity extraction, ontology-driven
categorization and document summarization.  They offer dozens of
languages.
</p>




<h3><a href="http://www.butlerhill.com/">Butler Hill Group</a></h3>

<p>&quot;The Butler Hill Group is a streamlined network of linguists,
computer scientists, language experts and research librarians with
expertise in the natural language issues of computer technology. We
maintain solid relationships with highly skilled consultants ...  our
past projects include machine translation, web search, lexicon
evaluation, product usability studies, speech and product localization
...&quot;</p>

<p>Butler Hill primarily provides services for corpus creation,
evaluation and internationalization.</p>



<h3><a href="http://company.carrot-search.com/index.html">Carrot Search</a></h3>
<p>
Carrot Search offers &quot;professional installation, customization, clustering and text mining consulting services based on Open Source and proprietary software.&quot;  They also offer <a href="http://company.carrot-search.com/lingo-applications.html">Lingo3G</a>, a
&quot;Document Clustering Engine that can organize
collections of text documents into clearly labeled thematic
groups. Accurately and on-the-fly.&quot;
</p>
<p>They also offer the open source framework <a
href="http://project.carrot2.org/">Carrot<sup>2</sup></a>, which
provides federated search with clustering over popular search engines and
APIs, including Lucene.
</p>

<h3><a href="http://clarabridge.com/">Clarabridge</a></h3>
<p> &quot;Clarabridge's text mining software transforms text into
actionable insight to improve market research, customer care, product
development, quality assurance and risk management. Clarabridge's
award-winning software links the worlds of text mining, search and
business intelligence (BI) to enable enterprises to more quickly and
intuitively leverage all of their data to make better business
decisions.&quot;  
</p>
<p>
They have a <a href="http://www.clarabridge.com/Portals/Clarabridge/technical.html">diagram
of their offerings</a>, which include data deduplication/cleansing, data linkage/merging,
document segmentation and categorization, entity extraction,
event, relationship and fact extraction, table parsing and image processing, as well
as search and visualization on top of these.
</p>


<h3><a href="http://www.clearforest.com/">ClearForest</a></h3>
<p>
&quot;ClearForest's text-driven business intelligence solutions help organizations make more informed business decisions by doing what search technologies do not--extract free text for use within analytics applications and BI systems. We provide the analytical bridge between two previously disconnected worlds of information--unstructured text and enterprise data. In allowing both to be analyzed simultaneously, ClearForest makes unified business intelligence a reality.&quot;
</p>
<p>
&quot;ClearForest Tags' open and flexible platform supports
statistical, structural and semantic tagging as well as custom
taggers, industry and custom taxonomies, and information agents.&quot;
</p>

<h3><a href="http://www.coderyte.com/">CodeRyte</a></h3>

<p>&quot;Trust, context and confidence anchor CodeRyte’s 
<a href="http://www.coderyte.com/approach/nlp/">natural language processing (NLP) technology</a>.&quot;
</p>
<p>
&quot;The technology ‘reads’ medical reports and identifies accurate CPT and ICD codes from the text of a physician’s documentation.&quot;  They very helpfully point to the American
Health Information Management Association's page on <a href="http://library.ahima.org/xpedio/groups/public/documents/ahima/bok1_025099.hcsp?dDocName=bok1_025099">Delving into Computer-assisted Coding</a>.
</p>


<h3><a href="http://www.cognia.com/index.htm">Cognia</a></h3>
<p>
&quot;Cognia develops and distributes information solutions for pharmaceutical and biotechnology companies that cost-effectively accelerate discovery and research processes.&quot;
</p>
<p>
&quot;The Cognia Molecular system is based on conclusions from our market research showing a critical unmet need of pharmaceutical, biotechnology, and non-profit research centers to make sense of and manage the growing tidal wave of information now available.&quot;
</p>

<h3><a href="http://www.cognition.com/">Cognition</a></h3>

<p> &quot;CognitionSearch, the Company's patented meaning-based
linguistic Search architecture, is able to deliver significantly
higher levels of relevant search results than is possible with
currently used Search technologies.&quot;
</p>

<p>&quot;The technology employs a unique mix of linguistics and
mathematical algorithms which has, in effect, 'taught' the computer
the meanings (or associated concepts) of nearly all the words and
frequently used ph rases within the common English language.  It also
has knowledge of the relations between words and phrases, especially
paraphrase and taxonomy.&quot;</p>

<p>&quot;CognitionSearch is the only commercially available technology
that combines natural langauge queries with linguistic meaning-based
Search and semantics.  It incorporates statistical algorithms with
linguistically mapped coverage of teh English language,...&quot;</p>


<h3><a href="http://www.connexor.com/">Connexor</a></h3>
<p>
&quot;Connexor provides linguistic technologies and expertise to
software houses and solution providers who tackle the challenge of how
to derive useful information from unstructured digital text for
different kinds of consumers and analysts.&quot;
</p>
<p>&quot;Connexor's Machinese software discovers the grammar and
semantics of natural language. Machinese enriches text with linguistic
markup: a uniform programmer's interface that enables use of text
content in software applications and solutions.&quot;
</p>
<p>
Connexor makes some excllent heuristic/rule-based part-of-speech taggers,
named entity extractors and dependency parsers.
</p>

<h3><a href="http://contentanalyst.com/">Content Analyst</a></h3>

<p> &quot;Stop searching, start doing.&quot; Content Analyst supplies
a range of text analytics applications, including <a
href="http://contentanalyst.com/html/technologies_categorization.html">classification</a>,
<a
href="http://contentanalyst.com/html/technologies_nametracking.html">named
entity coreference</a>, <a
href="http://contentanalyst.com/html/technologies_relationship.html">relationship
discovery</a>.  </p>

<p> Their technology is based on <a
href="http://contentanalyst.com/html/technologies_lsi.html">latent
semantic indexing</a>, a dimensionality reduction technique based on
singular value decomposition of a matrix of co-occurrences.  The
technology was acquired when Content Analyst <a
href="http://contentanalyst.com/html/whoweare_press_saic.html">spun
out from SAIC</a>.  </p>


<h3><a href="http://www.corporasoftware.com/">Corpora Software</a></h3>

<p> &quot;Corpora's Applied Linguistics software helps knowledge
workers find, read and understand textual information faster.&quot;
</p>
<p>In addition to enterprise search and collaboration, they 
do <a href="http://www.corporasoftware.com/products/summarize.aspx">document summarization</a>, <a href="http://www.corporasoftware.com/products/burst.aspx">news document topic clustering</a>,
and <a href="http://www.corporasoftware.com/products/sentiment.aspx">sentiment analysis</a>.
</p>

<h3><a href="http://www.crawdadtech.com/">Crawdad Technologies</a></h3>

<p>&quot;Crawdad Technologies, LLC provides software and services to
analysts and research professionals who need to transform unstructured
text into insight.&quot;</p>

<p>Crawdad supplies <a
href="http://www.crawdadtech.com/html/01_software.html">Crawdad
Desktop</a>, which does scraping and some natural langauge processing
involving classification and terminology extraction.</p>

<p>Crawdad also builds <a
href="http://www.crawdadtech.com/html/01_software.html">Listening
Posts</a>, which &quot;listens to blogs, discussion boards, chat
rooms, social networking sites, and online media for news or opinion
about products, brands, celebrities, and issues. Users view a daily
dashboard which uses patented natural language processing technology
to analyze the buzz on the Web and make sense of it.&quot;</p>


<h3><a href="http://www.engenium.com/">Engenium</a></h3>
<p>
&quot;Engenium is a pioneer in conceptual search technology that
increases the effectiveness of electronic information
retrieval. Unlike keyword searching that is limited to precisely
matching the language of a given query, Engenium's Semetric concept
search engines and integrated Autometric clustering engine analyze
documents by meaning, concept and context. This yields better, faster
search results --- uncovers information that otherwise would remain
buried --- and enables organizations to work smarter.&quot;
</p>
<p>They seem to be applying latent semantic analysis (a kind of
principal component analysis) to search and clustering.
</p>

<h3><a href="http://www.evri.com/">Evri</a></h3>

<p>&quot; Using semantic understanding of content, Evri is building the data graph of the web. We'll use this to create interesting and meaningful connections without having to search.&quot;</p>

<p>Evri <a
href="http://www.insightful.com/news_events/release.asp?RID=282">acquired
InFact</a> product from <a
href="http://www.insightful.com/">Insightful</a> when Evri was named
'Hypertext Solutions'.</p>


<h3><a href="http://www.fastsearch.com/">Fast</a></h3>
<p>
&quot;We do not simply search, we find. We filter out all the
irrelevant, peripheral data and provide the exact information end
users are looking for.&quot;
</p>
<p>&quot;We have solutions that monitor competitive intelligence,
provide brand and litigation protection, support regulatory and policy
compliance, and investigate criminal and terrorist activity. They
don't just return results, they return confidence and
protection.&quot;
</p>

<h3><a href="http://www.gd-ais.com/">General Dynamics Advanced Information System</a></h3>

<p> &quot;General Dynamics Advanced Information Systems designs,
develops, manufactures, and integrates information solutions for
defense, intelligence, space and homeland security communities.&quot;
</p>

<p> &quot;General Dynamics Advanced Information Systems uses data
mining technologies to help customers find new correlations, patterns
and trends. We use advanced technology to sift through large amounts
of data (structured data, text, audio, video, etc.) stored in
repositories and use pattern recognition and statistical and
mathematical techniques.&quot; In particular, their system
&quot;successfully performs entity extraction, a natural language
processing technique, to derive facts such as names, places,
organizations, locations and time from text.&quot;</p>



<h3><a href="http://ibm.com/">IBM</a></h3>
<p>
IBM has the IBM-SIRE Toolkit which allows for content extraction and
tagging of data. Not aware of its availability.
</p>

<h3><a href="http://www.expertsystem.net/">Expert System</a></h3>
<p>
Expert System is a &quot; leading provider of Semantic Intelligence software to discover, classify, and understand information contained in unstructured text. Expert System technology,  COGITO® enables natural language processing. It leverages full semantic analysis to automatically understand the content from any textual document, including the retrieval of meanings and the comprehension of natural language.
</p>
<p>
Semantic Intelligence enables you to read, understand, and extract the most relevant concepts present in the huge amount of documents, websites, presentations, emails and blogs that are accessible to us everyday. &quot;
</p>


<h3><a href="http://www.fetch.com/index.asp">Fetch</a></h3>
<p>
&quot;Fetch Technologies provides innovative solutions for integrating
and accessing heterogeneous data sources.&quot;
</p>
<p>
Fetch isn't so much a direct competitor, but more of a complementary
technology aimed at scraping web pages and record linkage (also known
as database deduplication).
</p>

<h3><a href="http://grammarsoft.com/">GrammarSoft</a></h3>
<p>&quot;GrammarSoft ApS is a small company specializing in Language
Technology.&quot; Product offerings (for multiple European languages)
include morphological analyzers, part-of-speech taggers,
syntactic/dependency parsing, named-entity recognition, translation,
and tools for teaching language and spell checking.  They are a
spinoff of the <a href="http://beta.visl.sdu.dk/">Visual Interactive
Syntax Learning</a> (VISL) project.
</p>


<h3><a href="http://www.infogistics.com/index.html">Infogistics</a></h3>
<p>
&quot;Infogistics are one of the leading companies providing
text-analysis, content extraction and document retrieval solutions
across multiple areas of industry including HR, law enforcement,
knowledge management and CRM.&quot;
</p>
<p>
&quot;Using advanced Natural Language processing technology developed
at Edinburgh University, Infogistics solutions enable information and
data contained in structured or unstructured text documents to be
retrieved, categorised, extracted and delivered to the right people at
the right time.&quot; Their NLP offerings include sentence
detection, part of speech tagging, and light syntactic chunking.  They
also offer higher-level products for specialized search, relationship
extraction and document parsing.
</p>

<h3><a href="http://www.inform.com">Inform</a></h3>
<p>
Inform does &quot;precise topic-based search for related
content&quot;.  Their technology involves text classification and
entity extraction for more-like-this applications.  You can
also check out the <a href="http://inform.com/index.aspx">Inform News Demo</a>.
Here's a 
paper explaining <a
href="http://www.inform.com/content/pdf/aynur-dayanik.pdf">Inform's
approach to text classification</a> (regularized logistic regression).
</p>


<h3><a href="http://www.inquira.com/">Inquira</a></h3>

<p>&quot;InQuira helps companies deliver more effective customer
service through their Web sites and contact centers.&quot; Their
product features &quot;integrated capabilities for natural language
search, knowledge base management, and analytics&quot;.
</p>

<p> Their product line includes <a
href="http://www.inquira.com/products_search.asp">InQuira Intelligent
Search</a>, &quot;a unified system that combines advanced linguistic
techniques and contextual understanding to provide unparalleled
capabilities for understanding, and responding to, the true intent
behind a user’s inquiry and browsing behavior.&quot;</p>



<h3><a href="http://www.intelligentresults.com/">Intelligent Results</a></h3>

<p> &quot;The <a href="http://www.intelligentresults.com/products/">PREDIGY</a> platform expedites the process of building,
simulating and deploying analytical decision applications. PREDIGY
integrates data exploration, predictive model development and
strategic planning and analysis. Once strategies are defined, the
platform generates fully functional scoring or decision
applications.&quot;
</p>

<p>PREDIGY consists of five modules, including <a
href="http://www.intelligentresults.com/products/discover/">IR
Discover</a>, which finds &quot;patterns hidden in various types of
data: structured (fields), semi-structured (codes) and unstructured
(text). Use discovered text patterns in predictive models and for
concept-based decision criteria in strategies.&quot; through the
extraction of &quot;key topics and concepts from unstructured content
using patented unstructured-text analysis and advanced data-mining
algorithms.&quot; </p>


<h3><a href="http://www.intelliresponse.com/">Intelliresponse</a></h3>

<p>&quot;IntelliResponse delivers on the promise of web self-service by providing one right answer to visitor questions.&quot; </p>

<p>Intelliresponse mainly works in question answering and
classification in the context of customer relationship management
(CRM).  About this they say their &quot;Patented 'one right answer'
solution understands precisely what the visitor wants, regardless of
the hundreds of ways a specific question can be asked&quot; They hedge
this a bit later by saying &quot;While it's not possible (or a good
idea) to create an IntelliResponse knowledge base that would answer
every possible question that anyone would ask, it is very possible to
create one that will answer upwards of 90% of incoming
questions.&quot;</p>

<p>You can even try it by entering a question on their home page.</p>



<h3><a href="http://www.inxight.com/">Inxight</a></h3>
<p>
&quot;Inxight is the leader in federated search, high-fidelity
extraction and visualization, enabling enterprise, government, and OEM
customers to discover, organize, and understand information contained
in unstructured text in all major languages.  Inxight solutions allow
its customers to access, cluster, and be alerted to relevant
information contained in the open Web, deep Web (patent databases, SEC
filings), subscription, and internal sources.&quot;
</p>
<p>
&quot;Inxight's deep understanding of all major languages, including
English, Arabic, German, French, Farsi, Spanish, and Simplified
Chinese, powers the ability to automatically identify and tag named
entities in a document -- such as persons, companies, places, weapons,
addresses and dates. It also identifies events - such as M&amp;A activity
and travel events - as well as relationships between entities.&quot;
</p>
<p>
They also have a <a
href="http://www.inxight.com/products/sdks/">software development
kit</a> (SDK) which includes entity extraction and visualization
components.
</p>


<h3><a href="">Irion</a></h3>

<p>&quot;Irion Technologies has succesfully picked up the challenge to
make computer programmes that make sense out of text, and really
understand human language.&quot;</p>

<p>&quot;Irion's software improves any web communication involving
human language, and applies to any organization in the world dealing
with textual information. This includes conceptual search, knowledge
management, E-commerce, customer support, and many other
applications.&quot;  Their technology seems to be
organized around classification.</p>  


<a name="janya"></a>
<h3><a href="">Janya</a></h3>

<p> &quot;Janya provides products and services to support information
discovery from unstructured and semi-structured data. With more than a
decade of experience developing and integrating this technology, Janya
works with customers and system integrators to incorporate information
discovery capability in both unclassified and classified
environments. By leveraging existing search technology and tools for
structured data analysis, Janya's solutions enable users to increase
their effective bandwidth to analyze text data streams.&quot;
</p>
<p> 
Janya builds <a
href="http://www.janyainc.com/products/products_semantex.php">Semantex</a>,
&quot;an enterprise-class information extraction system that supports
the automatic or semi-automatic analysis of large volumes of
electronic information in order to detect entities, attributes,
relationships and events. Semantex represents a hybrid model for
information extraction, combining machine-learning and grammatical
approaches to achieve better results than any of the techniques could
individually.&quot; They also build case restoration and &quot;text
zoning&quot;.  </p>
<p>
Note that Janya was a spinoff of Cymfony, and Cymfony is
now part of <a href="#tns">TNS Media Intelligence</a>.
</p>

<h3><a href="http://www.languagecomputer.com/">LCC (Language Computer Corporation)</a> </h3>
<p>
LCC has a suite of "Cicero" tools (CiceroLite, CiceroCustom) which do
content extraction.
</p>

<h3><a href="http://www.jodange.com/">Jodange</a></h3>
<p>
&quot;Predicting outcomes and planning strategy through deeper understanding of opinion holders' sentiment over time.&quot;
</p>
<p>
They supply an <a href="http://www.jodange.com/downloads.html">extensive list of whitepapers</a>.
</p>


<h3><a href="http://www.landcglobal.com/index.php">Language and Computing</a></h3>
<p>
&quot;Natural Language Processing (NLP) and Natural Language
Understanding (NLU) are technologies that can extract data and
information from free text documents for further processing. Language
and Computing (L&amp;C) is unique in delivering this level of
understanding through its integration of the world's largest medical
ontology with sophisticated linguistic processing algorithms.&quot;
</p>
<p>In addition to their own proprietary structured medical
&quot;knowledge bases&quot;, they offer search.  Their main offering
in NLP seems to be concept-based search and template filling, as
exemplified by their product for <a
href="http://www.landcglobal.com/pages/tessi.php">Terminology
Supported Semantic Indexing</a> product, for which they've provided an
<a
href="http://www.landcglobal.com/images/tessi_index.gif">architecture
diagram</a>.
</p>


<h3><a href="http://www.lexalytics.com/">LXA Lexalytics</a></h3>
<p>
&quot;Designed to help our customers address the basic problem of making their loosely structured information more valuable. We have created a set of products that attack the problem of discovering, understanding and acting on information that affects their business.&quot;
</p>
<p>
<a href="http://www.lexalytics.com/products/products.html">Lexalytics's products</a> include
entity extraction, relation extraction, document summarization, sentiment analysis,
and juddging from their <a href="http://www.lexalytics.com/news/news.html">press releases</a>,
they also do classification.
</p>
<p>
Lexalytics has an <a href="http://www.lexalytics.com/se3demo/demo.php">Entity Extraction Demo</a> online, which seems more focused on precision than recall.
</p>

<h3><a href="http://lexmasterclass.com/">Lexicography Master Class</a></h3>

<p> &quot;Lexicography MasterClass Ltd is a company specializing in
lexicography and lexical computing. We run training courses, design
and build language corpora, supply lexicographic software, and provide
a complete project-management service for lexicographic projects, from
conception to delivery.&quot;</p>


<h3><a href="http://www.lextek.com/">Lextek International</a></h3>
<p>
&quot;Lextek International supplies advanced information retrieval and natural language processing technology.&quot;
</p>
<p>
&quot;Our technologies are used in a wide variety of business
solutions. These range from document management systems to custom web
based applications.&quot;
</p>
<p>
Lextek supplies a general document classification engine,
a language identifier, and a documnt summarizer.
</p>

<h3><a href="http://www.linguamatics.com/">Linguamatics</a></h3>
<p>
&quot;Linguamatics enables organizations to reap maximum return from
their available knowledge assets, by the effective deployment of
advanced natural language processing technology.&quot;
</p>
<p>
They extract entities and relations from text, resolving them
against ontologies.
</p>

<h3><a href="http://linguit.com/">Linguit</a></h3>
<p>
Linguit's <a href="http://mynuggets.net/">Nuggets</a> is &quot;a
natural language enabled search engine for the mobile user and is the
first service of its kind.&quot;
</p>
<p>
Linguit's <a href="http://linguit.com/Services.en.html">services
page</a> indicates they are &quot;designing and developing software
components and applications in the domain of natural language
processing&quot;.  They mention stemmers, morphological and
syntactic analyzers, information retrieval, language understanding,
and text mining.
</p>

<h3><a href="http://www.lingway.com/">Lingway</a></h3>
<p>
Lingway is a &quot;specialized search engine company&quot; 
&quot; Lingway solutions are built around a set of NLP
components. These enable users to develop specific applications or to
enhance existing applications by adding linguistic capabilities.&quot;
</p>
<p> The list of components they provide is &quot; chunking,
clustering, parsing, semantic expander, spell checker, tagging, word
sense disambiguation ...&quot; 
</p>


<h3><a href="http://www.leximancer.com">Leximancer</a></h3>
<p>
&quot;Leximancer is a software tool that enables users to find meaning
from text-based documents. It automatically identifies key themes,
concepts and ideas from unstructured text with little or no
guidance.&quot;
</p>
<p>
Leximancer is focusing on word-based classification and automatic
taxonomy/synonym generation.
</p>

<h3><a href="http://www.lockheedmartin.com/wms/findPage.do?dsp=fec&amp;ci=11255&amp;sc=400">Lockheed Martin</a></h3>
<p>
&quot;The AeroTextTM product suite provides a fast, agile information
extraction system for developing knowledge-based content analysis
applications. Possible applications include automatic database
generation, routing, browsing, summarizing and searching.&quot;
</p>
<p>
They do named entity extraction, coreference resolution,
part-of-speech and phrase extraction, clustering, topic
categorization, and &quot;event&quot; extraction.  They train by
example and have special capabilities for reasoning about locations
and times.  They offer language support for English, Arabic, Chinese,
Spanash and Indonesian.
</p>

<h3><a href="http://www.matrixware.com/">Matrixware</a></h3>

<p>&quot;Utilizing and implementing up to date research results in the
fields of computer science, language technology, and information
theory we at Matrixware enable our customers to skilfully navigate the
endless sea of patent literature.&quot;</p>
	


<h3><a href="http://www.meaningfulmachines.com/index.htm">Meaningful Machines</a></h3>

<p>&quot;Meaningful Machines develops, patents, and commercializes language
technologies based on a unique suite of methods that automate machine
understanding of natural language. The company is developing
technologies for use in machine translation (MT), text mining, machine
learning, and other applications that benefit from machine
understanding.&quot;
</p>
<p>Although they cite very general problems, their 
<a href="http://www.meaningfulmachines.com/technologies.htm">technologies
page</a> only addresses machine translation.
</p>

<h3><a href="http://www.megaputer.com/">Megaputer</a></h3>
<p>
&quot;<a
href="http://www.megaputer.com/products/ta/index.php3">TextAnalyst</a>
will help you quickly summarize, efficiently navigate, and
cluster documents in your textbase.&quot;
</p>
<p>Megaputer's TextAnalyst product extracts semantic networks,
summarizes text using a &quot;balanced combination of
linguistic and neural network investigation methods&quot;.  Their notion
of semantic network is &quot;the most important concepts from
the text and the relations between these concepts weighted by
their relative importance&quot;.  They also use these semantic
networks for clustering and exploration/search.
</p>

<h3><a href="http://www.metacarta.com">MetaCarta</a></h3>
<p>
&quot;<a
href="http://www.metacarta.com/products/geographic-search.asp">GTS</a>
[Geographic Text Search] identifies implied and explicit references to
geographic locations within documents, assigns latitude/longitude
coordinates to the references, indexes the document, and then enables
a search for indexed documents through Graphical User Interfaces
(GUIs).&quot;
</p>
<p>
&quot;MetaCarta <a
href="http://www.metacarta.com/products/geotagger.asp">GeoTagger</a>
is a web service that geographically tags documents. The same core
natural language processing and GDM technology underlies both GTS and
GeoTagger.&quot;
</p>
<p>
MetaCarta specializes in location mention recognition and resolution
in text.  They use probabilistic models with confidence ranking.
</p>

<h3><a href="http://www.mnemonic.com">Mnemonic Technology</a></h3>
<p>
&quot;At Mnemonic, we can help you realize the full value of your information, whether structured or unstructured.&quot;
</p>
<p>
&quot;Our relevance models help you get the right information to the right people at the right time. They automatically learn to prioritize, categorize, monitor and summarize large volumes of unstructured textual information according to the unique requirements of individual users.&quot;
</p>
<p>
From what we can tell from their web site, their &quot;relevance
models&quot; learn scored text classifiers by example.  The only
application mentioned for text analytics is search query refinement.
</p>

<h3><a href="http://www.morphologic.hu/en/">Morphologic</a></h3>
<p>
Morphologic provides a range of products, mostly arranged around
morphologically sensitive bilingual translation dictionaries,
including thesauri.  Applications include copy editing such as
spelling checkers, hyphenators, grammar and style checkers; text
search tools including stemmers; and translation of full documents.
Tools include morphological analyzers including stemmers based on
unification grammars, syntactic analyzers, spell checkers and language
identifiers.
</p>

<h3><a href="http://www.netowl.com/">NetOwl</a></h3>
<p>
Extractor: &quot; Accurately perform entity extraction from
unstructured texts using advanced computational linguistics and
natural language processing.&quot;
</p>
<p>
Summarizer: &quot;Reliably generate abstracts and summaries of long
and complex documents.&quot;
</p>
<p>TextMiner: &quot;Empower users to find, organize, analyze, and mine a large volume of unstructured information using the the most advanced text analysis technology available.&quot;
</p>
<p>
They also run in several languages.  They have some kind of
cross-document coreference.  They spun out of <a
href="http://www.sra.com/">SRA International</a>. They claim to have
&quot;best-of-breed entity extraction&quot; and &quot;unique link and
event extraction&quot;, but don't explain what the breed is and don't
list any unique features of their link and event extractors.  They
even claim &quot;NetOwl posted the highest score ever achieved for
name extraction from unformatted text, a score which has never been
equaled by another system.&quot;, but don't provide any details.
</p>

<h3><a href="http://www.northernlight.com">Northern Light</a></h3>
<p>
&quot;What if your search engine could read all the market
intelligence reports and articles your company creates or licenses and
tell you what is in them, suggest to you what the business issues are
that they report on, and direct you to the documents that are the most
interesting to you, not from a search relevance perspective, but from
a meaning perspective?&quot;
</p>
<p> 
Northern Light offers <a
href="http://www.northernlight.com/mianalyst.html">Market Intelligence
Analyst</a>, which contains entity extraction, sentiment analysis,
relationship identification, meaning extraction and trend analysis.
There's a bit more information in their <a href="http://www.northernlight.com/downloads/MI_Analyst_Product_Sheet.pdf">MI Analyst Product Sheet</a>.
</p>


<h3><a href="http://northsideinc.com/">Northside</a></h3>

<p>&quot;We’re developing software that understands English, and can converse with people about a body of facts.&quot;.  Looks like they're still in the development phase,
but plan to use parsing to logical representations, ontologies
and natural language generation.&quot;</p>


<h3><a href="http://www.nstein.com/ntelligent.asp">Nstein</a></h3>
<p>
&quot;Ntelligent Enterprise Search by Nstein is a powerful search
solution built to increase the efficiency and productivity of your
employees on intranets and portals. For public websites, it will guide
your customers in the most advanced discovery process. It quickly
delivers highly accurate search results in all circumstances.&quot;
</p>
<p>
&quot;One suspicious letter. One dangerous passenger boarding a
routine flight. One viral infection in a small village, in a distant
country. These events have led to tragedies we all wish had never
happened. Critical information preceeded these events. Critical
information that could have been flagged by Nstein Technologies.&quot;
</p>
<p>Nstein was recently acquired by IBM, who maintain the brand.  Their
search is now a WebSphere (IBM's J2EE offering) OmniFind (IBM's search
offering) plugin. They do entity extraction, classification, and
clustering, as well as summarization (a.k.a. &quot;gisting&quot;)
coupled with machine translation.
</p>

<h3><a href="">Ontotext</a></h3>

<p> &quot;Ontotext is a leading developer of core semantic technology,
which delivers applications in domains like Web Mining, EAI, KM, BI,
and Media Research.&quot; </p>

<p> &quot;Ontotext is a laboratory of <a
href="http://www.sirma.com/en/index.jsp">Sirma</a>, active in several
research areas, including: Ontology Management; Information Extraction
and Retrieval (IE, IR); Semantic Web Services.&quot; Their products
include the <a
href="http://ontotext.com/kim/semanticannotation.html">KIM
Platform</a> for semantic annotation driven by a &quot;<a
href="http://ontotext.com/inference/semantic_repository.html">semantic
repository</a>&quot;.  The semantic annotation includes named-entity
extraction from a specified ontology.  They have <a href="http://ontotext.com/gate/index.html">contributed extensively to GATE</a> (for more info on GATE,
<a href="#gate">see above</a>).
</p>

<h3><a href="http://panscient.com/">Panscient</a></h3>

<p>&quot;Panscient is a content supplier for vertical search
engines.&quot; They have the interesting business model of supplying
<a href="http://panscient.com/products.htm">lists of people and
businesses</a> scraped from the entire <code>.com</code> domain of
corporate web sites and updated monthly.
They also develop <a href="http://panscient.com/services.htm">vertical 
search applications</a>.
</p>

<h3><a href="http://www.paritycomputing.com/web/index.html">Parity
Computing</a></h3> 

<p>&quot; Parity Computing's unstructured data management and
knowledge discovery solutions transform disparate data and content
into a knowledge network of actionable profiles and linked
relationships.&quot; </p>

<p>Parity offers the <a
href="http://www.paritycomputing.com/web/products/profiler_platform.html">Profiler System</a>,
which &quot;assembles and analyzes detailed profiles of key entities
such as people, institutions, and products, from disparate
unstructured documents and semi-structured data sources. ...
The key entities are extracted and assembled into distinct profiles using advanced machine learning heuristics. This includes normalization of spelling variations together with disambiguation of similarly-named entities (e.g. two people with the same name).&quot;
Additional functionality cited includes home page finding, extracting
patent references from web pages, etc.
</p>

<p>Parity also offers a lower level tool, the <a href="http://www.paritycomputing.com/web/products/reference_processor.html">Reference Processor</a>, a 
&quot;fully automated software engine for high-accuracy reference processing and linking of publication databases and bibliographies in arbitrary formats.&quot;.  Technology includes extraction, deduplication, clustering and
correction.</p>



<h3><a href="http://www.phrasetrain.com/">Phrasetrain</a></h3>
<p>
&quot;We're creating natural language technology that grows and improves as
it collects simple human judgments about language.  Using this
technology, we're building tools to search blog posts, feeds, and
other texts for key concepts, not just keywords and phrases. Think of
it as tagging meets natural language processing.&quot;  As of
February 2007, they only offered a mailing list.
</p>

<h3><a href="http://www.q-go.nl/">Q-go</a></h3>

<p>Their site's in Dutch, but it hints at natural language
search.</p>

<h3><a href="http://www.ql2.com/">QL2</a></h3>
<p>
&quot;QL2 Software's tools and solutions deliver business critical
data seamlessly and in real-time. QL2's technology integrates data
from virtually any source, inside and outside the firewall, with
existing applications and solutions. The result is better analytics
and smarter, more profitable decisions.&quot;
</p>
<p>
It wasn't clear from the web site whether any natural language
processing was involved in their <a href="http://www.ql2.com/products/">products</a>.
</p>

<h3><a href="http://rapid-i.com/">Rapid-i</a></h3> 
<p>
&quot;RapidMiner (formerly YALE) is the world-leading open-source
system for knowledge discovery and data mining. It is available in
different flavours: a free open-source version licensed under the GPL,
a free version with an improved user interface, and under a developer
license (OEM) which allows the integration of RapidMiner as a powerful
library even into proprietary products. Enhance your products with
adaptability and innovative analytical features. By now, thousands of
applications of RapidMiner in more than 30 countries give their users
a competitive edge.&quot;
</p>

<h3><a href="http://www.reeltwo.com/">Reel Two</a></h3>
<p>
&quot;Reel Two is tackling the tough problems in search and data analysis. Our software products and custom solutions provide scientists, analysts and managers with quick, intuitive access to the information that is most relevant to their work.&quot;
</p>
<p>
Reel Two spun out of the WEKA group at Waikato, and is primarily focused
on <a href="http://www.reeltwo.com/index.php?page=products&amp;subpage=cs">text classification</a> and <a href="http://www.reeltwo.com/index.php?page=products&amp;subpage=ee">entity extraction</a> as well as additional <a href="http://www.reeltwo.com/index.php?page=products">biomedical applications</a> aimed at chemical name resolution.
</p>

<h3><a href="http://www.sas.com">SAS</a></h3>
<p>
SAS <a
href="http://www.sas.com/technologies/analytics/datamining/textminer/">Text
Miner</a> &quot;provides a rich suite of tools for discovering and
extracting knowledge from text documents.  It transforms textual data
into a useable, intelligenble format that facilitates classifying
documents, finding explicit relationships or associations between
documents, clustering documents into categories and incorporating text
with other structured data to enrich predictive modeling
endeavors.&quot;
</p>
<p>
Text Miner includes format parsers, integrated GUIs and databases,
text parsing for terms or phrases, stemming, part-of-speech tagging,
and &quot;distillation&quot;.  It also includes &quot;data
cleaning&quot; and spelling correction.  Text Miner is also integrated
with their larger suite, <a
href="http://www.sas.com/technologies/analytics/datamining/miner/">Enterprise
Miner</a>, which supports classification and clustering.
</p>

<h3><a href="http://www.searchspark.com/">SearchSpark</a></h3>

<p> &quot;We are a semantic search startup with a passion for
organizing information to facilitate how people discover and filter
information to make better decisions.&quot;  Not much info,
as they say &quot;we are committed to launching in stealth mode&quot;.
</p>


<h3><a href="http://www.soliloquy.com/">Soliloquy</a></h3>
<p>
&quot;Soliloquy is the world's first company to offer 'intelligent,'
fully automated solutions that enable end users to find the
information, services and products they desire through targeted online
dialogs.&quot;
</p>
<p>
Soliloquy is in the business of <a href="http://www.soliloquy.com/solutions/dialog_mining.php">dialog mining</a>, a kind of text data mining over
dialogues. They claim to be &quot;the world's first company to offer turnkey solutions that enable end users to find the information and products they desire through intelligent, targeted dialogs.&quot;
</p>

<h3><a href="http://www.spss.com/text_mining_for_clementine/">SPSS</a></h3>
<p>
&quot;Text Mining for Clementine is a text mining workbench that enables you to extract key concepts, sentiments, and relationships from textual or "unstructured" data and convert them to a structured format that can be used to create predictive models.&quot;</p>




<h3><a href="http://www.summereyes.com/">Summer Eyes Software</a></h3>
<p>
&quot;Summer Eyes Software automates the extraction of value from
English text. Summer Eyes automatically 'reads' articles, emails, news
group postings, web pages, message boards, reviews, resumes, recipes
and other text.  It identifies topics, senses emotional tone, builds
outline structures, and notes references to people, companies,
products, relationships and events.&quot;
</p>
<p>
&quot;To make a long story short ....  Summer Eyes makes a long story,
short.&quot;
</p>
<p>
They seem to be using Danny Sleator's <a
href="http://www.link.cs.cmu.edu/link/">Link Grammar Parser</a>.
Among other things, they're working on the
<a href="http://www.pulsetrak.com/">PulseTrak</a> blog sentiment
analyzer.
</p>

<h3><a href="http://www.talkingdolphin.com/">Talking Dolphin</a></h3>
<p>
&quot;Talking Dolphin develops commercial software that enables
sophisticated processing of text documents, using state-of-the-art
technologies from the fields of artificial intelligence, machine
learning, and statistical natural language processing.&quot;
</p>
<p>
&quot;For example, our technology can be used to automatically
classify web pages into taxonomies, route customer support emails to
appropriate recipients, or extract structured information from web
pages.&quot;
</p>
<p>
They're mainly pushing their natural language classification software,
though they mention beta versions of clustering and future versions of
products such as named entity extraction and spelling correction.  <a
href="http://www.cs.berkeley.edu/~klein/">Dan Klein</a> and <a
href="http://www.stanford.edu/~grenager/">Ted Grenager</a>, two NLP
researchers, founded the company and form its management team.
</p>

<h3><a href="http://www.temis.com">Temis</a></h3>
<p>
&quot;TEMIS develops and markets corporate Text Mining solutions.  Our software unlocks knowledge from unstructured data.&quot;
</p>
<p>
Temis's <a href="http://www.temis.com/index.php?id=59&amp;selt=1">core products</a> include an
&quot;information extraction server dedicated to the analysis of text documents, a hierarchical clusterer that &quot;proposes the most relevant classification for a given document collection&quot;,
a classifier that &quot;classifies unstructured documents into pre-defined categories, combining statistical and linguistic analysis rules&quot;.  This is all based on &quot;XeLDA&quot;, their
&quot;multilingual linguistic engine&quot;.  They have an impressive <a href="http://www.temis.com/index.php?id=152&amp;selt=1">list of clients</a>.
</p>


<h3><a href="http://www.teragram.com/">Teragram</a></h3>
<p>
&quot;Teragram Corporation is the market leader in multilingual natural language processing technologies that use the meaning of text to distill relevant information from vast amounts of data.&quot;
</p>
<p>
Teragram provides, working top down, question answering,
classification, entity recognition, part-of-speech tagging,
morphological stemming, spelling correction, and various
search support tools such as language/charset ID.
</p>

<h3><a href="http://www.textanalysis.com/index.html">Text Analysis International</a></h3>
<p>
&quot;VisualText is the premier integrated development environment for
building information extraction systems, natural language processing
systems, and text analyzers.&quot;
</p>
<p>
TAI offers <a
href="http://www.textanalysis.com/Products/products.html">VisualText</a>,
&quot;an Integrated Development Environment for deep text analysis
applications.  Think of it as Visual C++ for Natural Language
Processing applications.  They also provide <a
href="http://www.textanalysis.com/Apps/Natural_Language_Processing/natural_language_processing.html">TAIParse</a>,
which includes part-of-speech tagging and noun-phrase chunking.  The
basic technology appears to be a <a href="http://www.textanalysis.com/tai-multi2003.pdf">multi-pass rule-based approach</a>.
</p>

<h3><a href="http://www.textore.net/index.html">TextOre</a></h3>

<p> &quot;We provide business-to-business (B2B) analytical software
and services to accurately examine and extract information from large
volumes of unstructured text.&quot;
</p>

<p> &quot;TextOre has the ability to perform searches that are highly
detailed, using multiple queries and in multiple languages, while
providing easily understood results. The results are provided
through an advanced visualization profile tool that identifies and
visually depicts the intensity of relationships in unstructured data
sources (letters, documents, e-mail and web pages), including
real-time news and information feeds. Our technology not only
identifies anomalies missed by competitive technologies, but also
identifies specific sentences, paragraphs and relationships, taking
into account the precise terms applied by a user.&quot; </p>

<h3><a href="http://www.textwise.com/">TextWise</a></h3>

<p> &quot;TextWise energizes your existing advertising portfolio by
offering high-resolution targeting, sophisticated media placement, and
hassle-free automation of both ad creation and placement.&quot;
</p>
<p> &quot;<a
href="http://www.textwise.com/semanticSignatures.html">Semantic
Signatures</a> are TextWise's patented contextual targeting
technology. They innovate beyond simple keyword-based or
category-based models currently used in so-called "contextual
advertising" and deliver a new level of context-driven advertisment
matching.&quot; They also
&quot;capture meaning through concepts, not keywords -- including multiple meanings and topics within a single document.&quot;
</p>

<a name="tns"></a>
<h3><a href="http://www.cymfony.com/index.html">TNS Media Intelligence/Cymfony</a></h3>
<p> &quot; Cymfony, a division of TNS Media Intelligence, is a market
influence analytics company that sifts and interprets the millions of
voices at the intersection of traditional and social media such as
blogs and social networks to gain consumer insight and develop
stronger bonds with influencers.&quot; 
</p>
<p> &quot;Cymfony's core is an advanced information extraction engine
that combines information retrieval and Natural Language Processing
(NLP) technologies to identify important people, places, companies,
concepts, relationships and events in documents.&quot; From the web
site, this looks like the latest version of Cymfony's &quot;InfoXtract
Engine&quot;.</p>
<p>
Cymfony spun off the government systems business to form
<a href="#janya">Janya</a>. 
</p>



<h3><a href="http://www.trifeed.com/">Trifeed</a></h3>
<p>
&quot;In a fully automated process BullDoc(tm) server will crawl your organization resources (shared directories, submitted emails, specific web sites), feed them to the information extraction engine that will save the extracted data into the database....The system comes with plug-ins for many applications (MSWord, outlook, numerous web browsers) that enable the user to view the documents/emails/web pages in the way he use to, only gives her the ability to browse and navigate within a document to the relevant information.
&quot;
</p>

<h3><a href="">Vantage Linguistics</a></h3>

<p>&quot;As a world leader in the development of linguistic software
solutions, Vantage Linguistics continues to set the benchmark for
innovation and excellence in language-based research and artificial
intelligence.&quot;</p>

<p>Vantage offers a <a
href="http://www.vantagelinguistics.com/products/">range of
products</a>, including language identifiers, spell checkers,
grammar checkers, and linguistically informed search.</p>


<h3><a href="http://www.xrce.xerox.com/competencies/content-analysis/homepage.en.html">Xerox European Research Centre</a></h3>
<p>
&quot;With the multiplication of on-line document repositories and the
phenomenal growth of the Web, a fantastic amount of information is
available at our fingertips. The central problem becomes that of
quickly accessing, within that mass, the arbitrary pieces of
information that are needed at any given time. As a large proportion
of the data is made up of natural language texts, any comprehensive
solution will rely heavily on natural language processing (NLP). Our
research agenda concerns theories, methods, tools and systems that
make it possible to uncover the content of natural language
texts.&quot;
</p>
<p>
XRCE provides demos and licenses for software for finite state automat,
machine learning for categorization and clustering, robust parsing
and semantics.  You can find some online demos and links to research
software from the above link.
</p>

<h3><a href="http://www.you-know.com/">You-Know</a></h3>
<p>
&quot;What we do: Collect and analyze Market Intelligence&quot;
</p>
<p>
They appear to do text document classification for sentiment,
survey analysis, email data mining, discussion/chat mining.
</p>


<h3><a href="http://www.zoominfo.com/">ZoomInfo</a></h3>
<p>
<a href="http://www.zoominfo.com/About/products/zoominfo.aspx">ZoomInfo.com</a> &quot;is the premier business information search engine, with
profiles on more than 35 million people and 3.8 million
companies. ZoomInfo delivers a single site for quick and easy access
to in-depth information on industries, companies, people, products,
services and jobs.&quot;  &quot;ZoomInfo, a semantic search engine, uses its patented Natural Language Processing algorithms to understand and organize the business web.&quot;
</p>
<p>
ZoomInfo focuses on search for people, companies or jobs
on <a href="http://www.zoominfo.com">zoominfo.com</a>.  
</p>


<h2>Lists of Tools and Corpora</h2>

<p>Lots of other groups have put together lists like this.  They contain
many links to one-off packages and many lists
almost all more comprehensive on the one-off packages (like Adwait
Ratnaparkhi's tagger, Michael Collins's parser, Eric Brill's tagger,
the YamCha SVM tagger, the Cambridge-CMU language toolkit, etc.)
</p>
<ul>
<li><a href="http://www-nlp.stanford.edu/links/statnlp.html">Stanford's Stat NLP/Corpus List</a></li>
<li><a href="http://www.ling.ohio-state.edu/~dickinso/corpus.html">Markus Dickinson's Corpora and Corpus Annotation List</a></li>
<li><a href="http://mallet.cs.umass.edu/index.php/Similar_software">MALLET's Similar Software Page</a></li>
<!-- <li><a href="http://compbio.uchsc.edu/corpora/bcresources.html">Alex Morgan's BioNLP Resource Page</a></li> -->
<li><a href="http://www.intelligent-web.org/wsm/tools/">intelligent-web.org's Web Search and Mining Page</a></li>
<li><a href="http://textanalytics.wikidot.com/">Text Analytics Wiki</a></li>
</ul>

</div><!-- content -->



<div id="foot">
<p>
&#169; 2003&ndash;2007 &nbsp;
<a href="mailto:lingpipe@alias-i.com">alias-i</a>
</p>
</div>
</body>
</html>


